{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 패키지 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PSPNet 네트워크 구성 및 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PSPNet, self).__init__()\n",
    "\n",
    "        # 파라미터 설정\n",
    "        block_config = [3, 4, 6, 3]  # resnet50\n",
    "        img_size = 475\n",
    "        img_size_8 = 60  # img_size의 1/8로 설정\n",
    "\n",
    "        # 4개의 모듈을 구성하는 서브 네트워크 준비\n",
    "        self.feature_conv = FeatureMap_convolution()\n",
    "        self.feature_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
    "        self.feature_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
    "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
    "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
    "\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[\n",
    "            6, 3, 2, 1], height=img_size_8, width=img_size_8)\n",
    "\n",
    "        self.decode_feature = DecodePSPFeature(\n",
    "            height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "        self.aux = AuxiliaryPSPlayers(\n",
    "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_conv(x)\n",
    "        x = self.feature_res_1(x)\n",
    "        x = self.feature_res_2(x)\n",
    "        x = self.feature_dilated_res_1(x)\n",
    "\n",
    "        output_aux = self.aux(x)  # Feature 모듈의 중간을 Aux 모듈로\n",
    "\n",
    "        x = self.feature_dilated_res_2(x)\n",
    "\n",
    "        x = self.pyramid_pooling(x)\n",
    "        output = self.decode_feature(x)\n",
    "\n",
    "        return (output, output_aux)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FeatureMap_convolution 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNormRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # inplase 설정으로, 입력을 저장하지 않고 출력을 계산하여 메모리 절약\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        outputs = self.relu(x)\n",
    "\n",
    "        return outputs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''구성할 네트워크 준비'''\n",
    "        super(FeatureMap_convolution, self).__init__()\n",
    "\n",
    "        # 합성곱 층1\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n",
    "        self.cbnr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # 합성곱 층2\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n",
    "        self.cbnr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # 합성곱 층3\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n",
    "        self.cbnr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # MaxPooling 층\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbnr_1(x)\n",
    "        x = self.cbnr_2(x)\n",
    "        x = self.cbnr_3(x)\n",
    "        outputs = self.maxpool(x)\n",
    "        return outputs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ResidualBlockPSP 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(ResidualBlockPSP, self).__init__()\n",
    "\n",
    "        # bottleNeckPSP를 준비\n",
    "        self.add_module(\n",
    "            \"block1\",\n",
    "            bottleNeckPSP(in_channels, mid_channels,\n",
    "                          out_channels, stride, dilation)\n",
    "        )\n",
    "\n",
    "        # bottleNeckIdentifyPSP 반복 준비\n",
    "        for i in range(n_blocks - 1):\n",
    "            self.add_module(\n",
    "                \"block\" + str(i+2),\n",
    "                bottleNeckIdentifyPSP(\n",
    "                    out_channels, mid_channels, stride, dilation)\n",
    "            )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bottleNeckPSP, bottleNeckIdentifyPSP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNorm, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        outputs = self.batchnorm(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(bottleNeckPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        # 스킵 결합\n",
    "        self.cb_residual = conv2DBatchNorm(\n",
    "            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = self.cb_residual(x)\n",
    "        return self.relu(conv + residual)\n",
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
    "        super(bottleNeckIdentifyPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = x\n",
    "        return self.relu(conv + residual)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pyramid Pooling 모듈  설명 및 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, height, width):\n",
    "        super(PyramidPooling, self).__init__()\n",
    "\n",
    "        # forward에 사용하는 화상 크기\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        # 각 합성곱 층의 출력 채널 수\n",
    "        out_channels = int(in_channels / len(pool_sizes))\n",
    "\n",
    "        # 각 합성곱 층을 작성\n",
    "        # 다음은 for문으로 구현하는 것이 낫지만, 이해를 돕기 위해 하나하나 나열하고 있습니다\n",
    "        # pool_sizes: [6, 3, 2, 1]\n",
    "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
    "        self.cbr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
    "        self.cbr_4 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.cbr_1(self.avpool_1(x))\n",
    "        out1 = F.interpolate(out1, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out2 = self.cbr_2(self.avpool_2(x))\n",
    "        out2 = F.interpolate(out2, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out3 = self.cbr_3(self.avpool_3(x))\n",
    "        out3 = F.interpolate(out3, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out4 = self.cbr_4(self.avpool_4(x))\n",
    "        out4 = F.interpolate(out4, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        # 최종적으로 결합시킬, dim=1으로 채널 수의 차원으로 결합\n",
    "        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return output\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decoder, AuxLoss 모듈 설명 및 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class DecodePSPFeature(nn.Module):\n",
    "    def __init__(self, height, width, n_classes):\n",
    "        super(DecodePSPFeature, self).__init__()\n",
    "\n",
    "        # forward에 사용하는 화상 크기\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n",
    "class AuxiliaryPSPlayers(nn.Module):\n",
    "    def __init__(self, in_channels, height, width, n_classes):\n",
    "        super(AuxiliaryPSPlayers, self).__init__()\n",
    "\n",
    "        # forward에 사용하는 화상 크기\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "net = PSPNet(n_classes=21)\n",
    "net"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (feature_conv): FeatureMap_convolution(\n",
       "    (cbnr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (feature_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block5): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block6): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pyramid_pooling): PyramidPooling(\n",
       "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
       "    (cbr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
       "    (cbr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
       "    (cbr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
       "    (cbr_4): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode_feature): DecodePSPFeature(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux): AuxiliaryPSPlayers(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "batch_size = 2\n",
    "\n",
    "dummy_img = torch.rand(batch_size, 3, 475,475)\n",
    "\n",
    "outputs = net(dummy_img)\n",
    "print(outputs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/plass-heesu/.conda/envs/tf2.5/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([[[[-1.5929e-01, -1.9692e-01, -2.3455e-01,  ...,  4.7098e-01,\n",
      "            5.6122e-01,  6.5145e-01],\n",
      "          [-1.3935e-01, -1.6518e-01, -1.9101e-01,  ...,  4.2524e-01,\n",
      "            5.1074e-01,  5.9624e-01],\n",
      "          [-1.1941e-01, -1.3344e-01, -1.4747e-01,  ...,  3.7950e-01,\n",
      "            4.6026e-01,  5.4102e-01],\n",
      "          ...,\n",
      "          [ 7.0662e-02,  5.4696e-02,  3.8730e-02,  ..., -2.2595e-01,\n",
      "           -2.1360e-01, -2.0125e-01],\n",
      "          [ 5.7415e-02,  3.4615e-02,  1.1814e-02,  ..., -3.2872e-01,\n",
      "           -3.2051e-01, -3.1230e-01],\n",
      "          [ 4.4168e-02,  1.4534e-02, -1.5101e-02,  ..., -4.3150e-01,\n",
      "           -4.2742e-01, -4.2335e-01]],\n",
      "\n",
      "         [[ 1.5179e-01,  1.3283e-01,  1.1387e-01,  ...,  1.5272e-02,\n",
      "           -1.1644e-02, -3.8561e-02],\n",
      "          [ 1.8196e-01,  1.5684e-01,  1.3172e-01,  ...,  1.0927e-02,\n",
      "           -1.4398e-02, -3.9723e-02],\n",
      "          [ 2.1213e-01,  1.8085e-01,  1.4956e-01,  ...,  6.5809e-03,\n",
      "           -1.7152e-02, -4.0885e-02],\n",
      "          ...,\n",
      "          [-8.8323e-02, -4.4387e-02, -4.5059e-04,  ..., -9.4203e-02,\n",
      "           -1.1108e-01, -1.2796e-01],\n",
      "          [-1.0039e-01, -5.0895e-02, -1.4035e-03,  ..., -8.2469e-02,\n",
      "           -1.0433e-01, -1.2620e-01],\n",
      "          [-1.1245e-01, -5.7403e-02, -2.3564e-03,  ..., -7.0734e-02,\n",
      "           -9.7586e-02, -1.2444e-01]],\n",
      "\n",
      "         [[ 2.9997e-01,  2.9881e-01,  2.9764e-01,  ...,  5.1487e-01,\n",
      "            5.9926e-01,  6.8365e-01],\n",
      "          [ 2.7244e-01,  2.7734e-01,  2.8225e-01,  ...,  4.7451e-01,\n",
      "            5.5180e-01,  6.2909e-01],\n",
      "          [ 2.4490e-01,  2.5588e-01,  2.6686e-01,  ...,  4.3415e-01,\n",
      "            5.0433e-01,  5.7452e-01],\n",
      "          ...,\n",
      "          [ 1.0210e+00,  1.0112e+00,  1.0014e+00,  ...,  7.8473e-01,\n",
      "            8.1414e-01,  8.4356e-01],\n",
      "          [ 1.0709e+00,  1.0584e+00,  1.0459e+00,  ...,  7.9830e-01,\n",
      "            8.2085e-01,  8.4341e-01],\n",
      "          [ 1.1209e+00,  1.1056e+00,  1.0903e+00,  ...,  8.1188e-01,\n",
      "            8.2757e-01,  8.4325e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6151e-01,  1.4677e-01,  1.3203e-01,  ..., -5.8796e-02,\n",
      "           -8.8766e-02, -1.1874e-01],\n",
      "          [ 1.5426e-01,  1.3954e-01,  1.2482e-01,  ..., -4.6633e-02,\n",
      "           -7.6786e-02, -1.0694e-01],\n",
      "          [ 1.4701e-01,  1.3231e-01,  1.1761e-01,  ..., -3.4470e-02,\n",
      "           -6.4807e-02, -9.5143e-02],\n",
      "          ...,\n",
      "          [ 6.6621e-02,  5.8499e-02,  5.0377e-02,  ..., -4.5174e-01,\n",
      "           -4.7197e-01, -4.9220e-01],\n",
      "          [ 1.7090e-02,  1.7474e-02,  1.7859e-02,  ..., -4.5304e-01,\n",
      "           -4.7795e-01, -5.0287e-01],\n",
      "          [-3.2441e-02, -2.3550e-02, -1.4659e-02,  ..., -4.5434e-01,\n",
      "           -4.8394e-01, -5.1353e-01]],\n",
      "\n",
      "         [[-3.4670e-03,  8.7199e-03,  2.0907e-02,  ..., -1.1466e-01,\n",
      "           -1.5519e-01, -1.9572e-01],\n",
      "          [ 4.4495e-03,  1.8126e-02,  3.1803e-02,  ..., -1.3617e-01,\n",
      "           -1.7262e-01, -2.0907e-01],\n",
      "          [ 1.2366e-02,  2.7533e-02,  4.2700e-02,  ..., -1.5769e-01,\n",
      "           -1.9006e-01, -2.2243e-01],\n",
      "          ...,\n",
      "          [-7.3924e-02, -8.5666e-02, -9.7407e-02,  ..., -2.4809e-01,\n",
      "           -2.3775e-01, -2.2741e-01],\n",
      "          [-7.0075e-02, -8.7264e-02, -1.0445e-01,  ..., -2.6862e-01,\n",
      "           -2.5055e-01, -2.3249e-01],\n",
      "          [-6.6226e-02, -8.8862e-02, -1.1150e-01,  ..., -2.8915e-01,\n",
      "           -2.6336e-01, -2.3756e-01]],\n",
      "\n",
      "         [[ 5.8087e-01,  6.0038e-01,  6.1989e-01,  ...,  5.2129e-01,\n",
      "            5.1831e-01,  5.1534e-01],\n",
      "          [ 5.6946e-01,  5.8278e-01,  5.9609e-01,  ...,  4.9003e-01,\n",
      "            4.9385e-01,  4.9767e-01],\n",
      "          [ 5.5804e-01,  5.6517e-01,  5.7230e-01,  ...,  4.5878e-01,\n",
      "            4.6939e-01,  4.8000e-01],\n",
      "          ...,\n",
      "          [ 2.2962e-01,  2.5005e-01,  2.7048e-01,  ...,  2.6666e-01,\n",
      "            2.7613e-01,  2.8559e-01],\n",
      "          [ 2.0806e-01,  2.4056e-01,  2.7306e-01,  ...,  2.7167e-01,\n",
      "            2.7940e-01,  2.8714e-01],\n",
      "          [ 1.8651e-01,  2.3107e-01,  2.7563e-01,  ...,  2.7668e-01,\n",
      "            2.8268e-01,  2.8868e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6142e-02,  1.0994e-01,  1.3374e-01,  ...,  3.0495e-01,\n",
      "            3.2880e-01,  3.5265e-01],\n",
      "          [ 1.0261e-01,  1.2217e-01,  1.4173e-01,  ...,  2.7629e-01,\n",
      "            2.9450e-01,  3.1270e-01],\n",
      "          [ 1.1908e-01,  1.3440e-01,  1.4973e-01,  ...,  2.4763e-01,\n",
      "            2.6019e-01,  2.7276e-01],\n",
      "          ...,\n",
      "          [-1.8370e-01, -1.4747e-01, -1.1125e-01,  ..., -1.2861e-01,\n",
      "           -1.5859e-01, -1.8857e-01],\n",
      "          [-2.2405e-01, -1.8319e-01, -1.4233e-01,  ..., -1.8967e-01,\n",
      "           -2.3303e-01, -2.7639e-01],\n",
      "          [-2.6439e-01, -2.1890e-01, -1.7342e-01,  ..., -2.5073e-01,\n",
      "           -3.0747e-01, -3.6421e-01]],\n",
      "\n",
      "         [[ 2.3790e-01,  2.1015e-01,  1.8240e-01,  ..., -2.1227e-02,\n",
      "            7.9723e-03,  3.7172e-02],\n",
      "          [ 2.6354e-01,  2.2849e-01,  1.9344e-01,  ..., -6.0737e-02,\n",
      "           -3.9202e-02, -1.7668e-02],\n",
      "          [ 2.8918e-01,  2.4683e-01,  2.0447e-01,  ..., -1.0025e-01,\n",
      "           -8.6377e-02, -7.2508e-02],\n",
      "          ...,\n",
      "          [ 1.3492e-02, -2.1008e-02, -5.5508e-02,  ..., -2.0970e-01,\n",
      "           -1.8967e-01, -1.6965e-01],\n",
      "          [-4.2787e-03, -2.9574e-02, -5.4868e-02,  ..., -2.1252e-01,\n",
      "           -1.9594e-01, -1.7935e-01],\n",
      "          [-2.2050e-02, -3.8139e-02, -5.4229e-02,  ..., -2.1534e-01,\n",
      "           -2.0220e-01, -1.8906e-01]],\n",
      "\n",
      "         [[ 2.8025e-01,  2.3290e-01,  1.8555e-01,  ...,  3.6287e-01,\n",
      "            4.3685e-01,  5.1082e-01],\n",
      "          [ 2.7883e-01,  2.3945e-01,  2.0007e-01,  ...,  3.5142e-01,\n",
      "            4.0848e-01,  4.6553e-01],\n",
      "          [ 2.7740e-01,  2.4599e-01,  2.1459e-01,  ...,  3.3998e-01,\n",
      "            3.8011e-01,  4.2025e-01],\n",
      "          ...,\n",
      "          [ 2.5965e-01,  3.0425e-01,  3.4885e-01,  ...,  4.2584e-01,\n",
      "            3.5408e-01,  2.8231e-01],\n",
      "          [ 2.3939e-01,  2.8888e-01,  3.3836e-01,  ...,  4.8344e-01,\n",
      "            4.0639e-01,  3.2933e-01],\n",
      "          [ 2.1914e-01,  2.7351e-01,  3.2787e-01,  ...,  5.4105e-01,\n",
      "            4.5870e-01,  3.7636e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.5407e-02, -2.2740e-02,  1.9927e-02,  ..., -9.7237e-02,\n",
      "           -7.8942e-02, -6.0648e-02],\n",
      "          [-5.0454e-02, -1.5443e-02,  1.9568e-02,  ..., -6.1853e-02,\n",
      "           -4.3680e-02, -2.5507e-02],\n",
      "          [-3.5502e-02, -8.1462e-03,  1.9209e-02,  ..., -2.6468e-02,\n",
      "           -8.4168e-03,  9.6346e-03],\n",
      "          ...,\n",
      "          [-2.4385e-01, -2.6791e-01, -2.9198e-01,  ..., -2.7956e-01,\n",
      "           -2.6662e-01, -2.5369e-01],\n",
      "          [-2.8448e-01, -3.0930e-01, -3.3412e-01,  ..., -3.2486e-01,\n",
      "           -3.2226e-01, -3.1967e-01],\n",
      "          [-3.2511e-01, -3.5068e-01, -3.7625e-01,  ..., -3.7016e-01,\n",
      "           -3.7790e-01, -3.8564e-01]],\n",
      "\n",
      "         [[ 3.6601e-01,  2.9141e-01,  2.1680e-01,  ..., -1.5653e-01,\n",
      "           -1.6423e-01, -1.7192e-01],\n",
      "          [ 3.4292e-01,  2.7834e-01,  2.1375e-01,  ..., -1.3609e-01,\n",
      "           -1.4314e-01, -1.5019e-01],\n",
      "          [ 3.1983e-01,  2.6527e-01,  2.1070e-01,  ..., -1.1566e-01,\n",
      "           -1.2205e-01, -1.2845e-01],\n",
      "          ...,\n",
      "          [ 2.4038e-01,  1.8431e-01,  1.2824e-01,  ..., -3.2631e-02,\n",
      "            1.2024e-02,  5.6679e-02],\n",
      "          [ 2.1029e-01,  1.4393e-01,  7.7573e-02,  ..., -2.7732e-02,\n",
      "            1.8024e-02,  6.3779e-02],\n",
      "          [ 1.8021e-01,  1.0356e-01,  2.6903e-02,  ..., -2.2832e-02,\n",
      "            2.4023e-02,  7.0879e-02]],\n",
      "\n",
      "         [[ 5.6075e-01,  5.2834e-01,  4.9592e-01,  ...,  5.2966e-01,\n",
      "            5.8142e-01,  6.3318e-01],\n",
      "          [ 5.6183e-01,  5.3147e-01,  5.0110e-01,  ...,  5.4480e-01,\n",
      "            5.9247e-01,  6.4015e-01],\n",
      "          [ 5.6291e-01,  5.3460e-01,  5.0628e-01,  ...,  5.5994e-01,\n",
      "            6.0353e-01,  6.4711e-01],\n",
      "          ...,\n",
      "          [ 1.9513e-02,  1.5058e-03, -1.6501e-02,  ...,  1.3465e-01,\n",
      "            1.3402e-01,  1.3339e-01],\n",
      "          [-3.9045e-02, -5.1462e-02, -6.3878e-02,  ...,  1.0461e-01,\n",
      "            1.0414e-01,  1.0367e-01],\n",
      "          [-9.7603e-02, -1.0443e-01, -1.1126e-01,  ...,  7.4574e-02,\n",
      "            7.4267e-02,  7.3960e-02]]]], grad_fn=<UpsampleBilinear2DBackward1>), tensor([[[[-0.9387, -0.9673, -0.9960,  ..., -0.8273, -0.8110, -0.7947],\n",
      "          [-0.8884, -0.9167, -0.9451,  ..., -0.8110, -0.7917, -0.7725],\n",
      "          [-0.8381, -0.8661, -0.8941,  ..., -0.7946, -0.7724, -0.7502],\n",
      "          ...,\n",
      "          [-0.7392, -0.7281, -0.7170,  ..., -0.3314, -0.3169, -0.3025],\n",
      "          [-0.7179, -0.7068, -0.6956,  ..., -0.3528, -0.3367, -0.3205],\n",
      "          [-0.6967, -0.6854, -0.6742,  ..., -0.3742, -0.3564, -0.3386]],\n",
      "\n",
      "         [[-0.1187, -0.1450, -0.1712,  ..., -0.1962, -0.1337, -0.0713],\n",
      "          [-0.1484, -0.1738, -0.1992,  ..., -0.1935, -0.1337, -0.0738],\n",
      "          [-0.1780, -0.2027, -0.2273,  ..., -0.1909, -0.1336, -0.0762],\n",
      "          ...,\n",
      "          [-0.2489, -0.2320, -0.2152,  ...,  0.1429,  0.1896,  0.2362],\n",
      "          [-0.2371, -0.2226, -0.2080,  ...,  0.1775,  0.2218,  0.2660],\n",
      "          [-0.2254, -0.2131, -0.2007,  ...,  0.2121,  0.2539,  0.2957]],\n",
      "\n",
      "         [[-0.2873, -0.2274, -0.1674,  ..., -0.1595, -0.1018, -0.0441],\n",
      "          [-0.2313, -0.1820, -0.1327,  ..., -0.1382, -0.0776, -0.0170],\n",
      "          [-0.1752, -0.1366, -0.0980,  ..., -0.1169, -0.0534,  0.0101],\n",
      "          ...,\n",
      "          [-0.0108, -0.0256, -0.0405,  ..., -0.4099, -0.3818, -0.3537],\n",
      "          [-0.0542, -0.0674, -0.0806,  ..., -0.4709, -0.4283, -0.3856],\n",
      "          [-0.0977, -0.1092, -0.1208,  ..., -0.5319, -0.4747, -0.4176]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3759,  0.3056,  0.2354,  ...,  0.0095,  0.0114,  0.0134],\n",
      "          [ 0.3997,  0.3368,  0.2738,  ...,  0.0297,  0.0323,  0.0349],\n",
      "          [ 0.4235,  0.3679,  0.3123,  ...,  0.0499,  0.0531,  0.0564],\n",
      "          ...,\n",
      "          [ 0.2407,  0.2292,  0.2178,  ...,  0.1193,  0.1099,  0.1005],\n",
      "          [ 0.2907,  0.2733,  0.2559,  ...,  0.1308,  0.1185,  0.1063],\n",
      "          [ 0.3408,  0.3174,  0.2940,  ...,  0.1422,  0.1272,  0.1121]],\n",
      "\n",
      "         [[-0.3317, -0.3217, -0.3116,  ..., -0.3316, -0.3332, -0.3349],\n",
      "          [-0.3133, -0.2998, -0.2862,  ..., -0.3675, -0.3762, -0.3848],\n",
      "          [-0.2949, -0.2778, -0.2608,  ..., -0.4035, -0.4191, -0.4347],\n",
      "          ...,\n",
      "          [-0.6545, -0.6057, -0.5570,  ..., -0.4306, -0.4309, -0.4312],\n",
      "          [-0.6219, -0.5777, -0.5336,  ..., -0.4552, -0.4548, -0.4544],\n",
      "          [-0.5892, -0.5497, -0.5102,  ..., -0.4797, -0.4787, -0.4777]],\n",
      "\n",
      "         [[-0.0225, -0.0417, -0.0609,  ...,  0.1977,  0.2289,  0.2600],\n",
      "          [-0.0477, -0.0592, -0.0706,  ...,  0.1718,  0.1944,  0.2170],\n",
      "          [-0.0728, -0.0766, -0.0804,  ...,  0.1458,  0.1599,  0.1740],\n",
      "          ...,\n",
      "          [-0.3627, -0.3388, -0.3150,  ..., -0.1183, -0.0905, -0.0627],\n",
      "          [-0.3191, -0.3037, -0.2883,  ..., -0.1584, -0.1226, -0.0868],\n",
      "          [-0.2754, -0.2685, -0.2616,  ..., -0.1985, -0.1547, -0.1108]]],\n",
      "\n",
      "\n",
      "        [[[-0.8867, -0.8915, -0.8963,  ..., -0.9566, -0.9438, -0.9310],\n",
      "          [-0.8825, -0.8883, -0.8942,  ..., -0.8733, -0.8551, -0.8368],\n",
      "          [-0.8784, -0.8852, -0.8920,  ..., -0.7900, -0.7663, -0.7427],\n",
      "          ...,\n",
      "          [-0.5878, -0.5720, -0.5562,  ..., -0.4477, -0.5337, -0.6197],\n",
      "          [-0.5108, -0.5066, -0.5024,  ..., -0.4889, -0.5976, -0.7063],\n",
      "          [-0.4338, -0.4412, -0.4486,  ..., -0.5302, -0.6615, -0.7928]],\n",
      "\n",
      "         [[-0.1551, -0.2046, -0.2542,  ..., -0.2020, -0.1655, -0.1291],\n",
      "          [-0.1287, -0.1761, -0.2236,  ..., -0.1938, -0.1611, -0.1283],\n",
      "          [-0.1023, -0.1476, -0.1930,  ..., -0.1857, -0.1566, -0.1275],\n",
      "          ...,\n",
      "          [-0.0591, -0.0308, -0.0024,  ...,  0.1564,  0.1477,  0.1389],\n",
      "          [-0.1202, -0.0692, -0.0183,  ...,  0.2033,  0.2013,  0.1992],\n",
      "          [-0.1812, -0.1077, -0.0342,  ...,  0.2503,  0.2549,  0.2595]],\n",
      "\n",
      "         [[ 0.0378,  0.0145, -0.0088,  ..., -0.2055, -0.2649, -0.3243],\n",
      "          [ 0.0909,  0.0598,  0.0288,  ..., -0.1651, -0.2171, -0.2692],\n",
      "          [ 0.1439,  0.1052,  0.0665,  ..., -0.1248, -0.1694, -0.2140],\n",
      "          ...,\n",
      "          [ 0.0067, -0.0241, -0.0550,  ..., -0.6977, -0.7243, -0.7509],\n",
      "          [-0.0545, -0.0893, -0.1240,  ..., -0.7648, -0.7931, -0.8214],\n",
      "          [-0.1158, -0.1544, -0.1930,  ..., -0.8319, -0.8619, -0.8919]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2519,  0.2175,  0.1831,  ..., -0.0486, -0.0308, -0.0131],\n",
      "          [ 0.2007,  0.1833,  0.1660,  ..., -0.0506, -0.0473, -0.0440],\n",
      "          [ 0.1495,  0.1491,  0.1488,  ..., -0.0526, -0.0637, -0.0748],\n",
      "          ...,\n",
      "          [-0.0707, -0.0468, -0.0230,  ...,  0.0670,  0.1135,  0.1600],\n",
      "          [-0.0623, -0.0361, -0.0099,  ...,  0.0731,  0.1261,  0.1790],\n",
      "          [-0.0539, -0.0254,  0.0032,  ...,  0.0792,  0.1386,  0.1980]],\n",
      "\n",
      "         [[-0.4540, -0.4841, -0.5142,  ..., -0.5206, -0.5878, -0.6551],\n",
      "          [-0.4959, -0.5104, -0.5250,  ..., -0.4957, -0.5630, -0.6304],\n",
      "          [-0.5378, -0.5368, -0.5358,  ..., -0.4708, -0.5383, -0.6058],\n",
      "          ...,\n",
      "          [-0.5991, -0.5980, -0.5969,  ..., -0.6231, -0.7091, -0.7952],\n",
      "          [-0.6070, -0.6045, -0.6021,  ..., -0.6158, -0.7101, -0.8043],\n",
      "          [-0.6148, -0.6110, -0.6073,  ..., -0.6086, -0.7110, -0.8134]],\n",
      "\n",
      "         [[-0.3362, -0.3196, -0.3030,  ...,  0.2027,  0.2327,  0.2627],\n",
      "          [-0.3344, -0.3263, -0.3181,  ...,  0.1614,  0.1876,  0.2139],\n",
      "          [-0.3327, -0.3330, -0.3332,  ...,  0.1200,  0.1425,  0.1650],\n",
      "          ...,\n",
      "          [-0.4804, -0.4371, -0.3939,  ..., -0.1818, -0.1144, -0.0469],\n",
      "          [-0.5728, -0.5188, -0.4648,  ..., -0.1943, -0.1224, -0.0505],\n",
      "          [-0.6652, -0.6005, -0.5357,  ..., -0.2067, -0.1304, -0.0540]]]],\n",
      "       grad_fn=<UpsampleBilinear2DBackward1>))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf2.5': conda)"
  },
  "interpreter": {
   "hash": "8713644ccf95bc94f9cdb73f3820952989f55b48f58b1b4cb3d9529941d252d1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}