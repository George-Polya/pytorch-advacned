{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 패키지 import\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# 초기설정\n",
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습 및 검증 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from utils.dataloader import make_datapath_list, DataTransform, VOCDataset\n",
    "\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath=rootpath)\n",
    "\n",
    "color_mean = (0.485, 0.456, 0.406)\n",
    "color_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders_dict ={\"train\":train_dataloader, \"val\":val_dataloader}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from utils.pspnet import PSPNet\n",
    "\n",
    "# ADE20K 모델로드 \n",
    "net = PSPNet(n_classes=150)\n",
    "\n",
    "state_dict = torch.load(\"./weights/pspnet50_ADE20K.pth\")\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "# 분류용 합성곱 층을 21로 바꿈\n",
    "n_classes = 21\n",
    "net.decode_feature.classification = nn.Conv2d(in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "net.aux.classification = nn.Conv2d(in_channels=256,out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "net.decode_feature.classification.apply(weights_init)\n",
    "net.aux.classification.apply(weights_init)\n",
    "\n",
    "print(\"네트워크 설정 완료: 학습된 가중치를 로드했습니다\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "네트워크 설정 완료: 학습된 가중치를 로드했습니다\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 손실 함수 정의\n",
    "class PSPLoss(nn.Module):\n",
    "    def __init__(self, aux_weight=0.4):\n",
    "        super(PSPLoss, self).__init__()\n",
    "        self.aux_weight = aux_weight\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "\n",
    "        loss = F.cross_entropy(outputs[0], targets, reduction=\"mean\")\n",
    "        loss_aux = F.cross_entropy(outputs[1], targets, reduction=\"mean\")\n",
    "\n",
    "        return loss + self.aux_weight * loss_aux\n",
    "\n",
    "criterion = PSPLoss(aux_weight=0.4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 스케줄러로 에폭별 학습 비율 변경\n",
    "- 에폭에 따라 학습률을 변화시키는 스케줄러 사용"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "optimizer = optim.SGD([\n",
    "    {\"params\": net.feature_conv.parameters(), \"lr\":1e-3},\n",
    "    {\"params\": net.feature_res_1.parameters(), \"lr\":1e-3},\n",
    "    {\"params\": net.feature_res_2.parameters(), \"lr\":1e-3},\n",
    "    {\"params\": net.feature_dilated_res_1.parameters(), \"lr\":1e-3},\n",
    "    {\"params\": net.feature_dilated_res_2.parameters(), \"lr\":1e-3},\n",
    "    {\"params\": net.pyramid_pooling.parameters(), \"lr\":1e-3},\n",
    "    {\"params\": net.decode_feature.parameters(), \"lr\":1e-2},\n",
    "    {\"params\": net.aux.parameters(), \"lr\":1e-2},\n",
    "], momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "def lambda_epoch(epoch):\n",
    "    max_epoch = 30\n",
    "    return math.pow((1-epoch / max_epoch), 0.9)\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs):\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"사용 장치: \", device)\n",
    "\n",
    "    net.to(device)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
    "    num_val_imgs = len(dataloaders_dict[\"val\"].dataset)\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "\n",
    "    batch_multiplier = 3\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        print(\"-----------------------\")\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                print(\" (train) \")\n",
    "\n",
    "            else:\n",
    "                if((epoch+1) % 5 == 0):\n",
    "                    net.eval()\n",
    "                    print(\"-----------------------\")\n",
    "                    print(\" (val) \")\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            count = 0\n",
    "            for imges, anno_class_imges in dataloaders_dict[phase]:\n",
    "                if imges.size()[0] == 1:\n",
    "                    continue\n",
    "\n",
    "                imges = imges.to(device)\n",
    "                anno_class_imges = anno_class_imges.to(device)\n",
    "\n",
    "                if (phase == \"train\") and (count == 0):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    count = batch_multiplier\n",
    "\n",
    "                with torch.set_grad_enabled(phase ==\"train\"):\n",
    "                    outputs = net(imges)\n",
    "                    loss = criterion(outputs, anno_class_imges.long()) / batch_multiplier\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        count -= 1\n",
    "\n",
    "                        if (iteration % 10 == 0):\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print(\"반복 {} || Loss: {:4f} || 10iter: {:.4f} sec.\".format(iteration, loss.item()/batch_size*batch_multiplier, duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item() * batch_multiplier\n",
    "                        iteration += 1\n",
    "\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item() * batch_multiplier\n",
    "        \n",
    "        t_epoch_finish = time.time()\n",
    "        print(\"-------------\")\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss/num_train_imgs, epoch_val_loss/num_val_imgs))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        log_epoch = {\"epoch\" : epoch+1, \"train_loss\":epoch_train_loss / num_train_imgs, \"val_loss\":epoch_val_loss/num_val_imgs}\n",
    "        logs.append(log_epoch)\n",
    "\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\")\n",
    "    \n",
    "    torch.save(net.state_dict(), \"weights/pspnet50_\"+str(epoch+1)+\".pth\")\n",
    "\n",
    "    \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "num_epochs = 5\n",
    "train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "사용 장치:  cuda:1\n",
      "-----------------------\n",
      "Epoch 1/5\n",
      "-----------------------\n",
      " (train) \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/plass-heesu/.conda/envs/tf2.5/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/plass-heesu/.conda/envs/tf2.5/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "반복 10 || Loss: 0.417579 || 10iter: 13.6435 sec.\n",
      "반복 20 || Loss: 0.493122 || 10iter: 9.0591 sec.\n",
      "반복 30 || Loss: 0.154389 || 10iter: 8.4469 sec.\n",
      "반복 40 || Loss: 0.249624 || 10iter: 8.3748 sec.\n",
      "반복 50 || Loss: 0.114953 || 10iter: 8.4954 sec.\n",
      "반복 60 || Loss: 0.122395 || 10iter: 9.0559 sec.\n",
      "반복 70 || Loss: 0.170661 || 10iter: 8.5380 sec.\n",
      "반복 80 || Loss: 0.123969 || 10iter: 8.1906 sec.\n",
      "반복 90 || Loss: 0.091108 || 10iter: 8.2258 sec.\n",
      "반복 100 || Loss: 0.156867 || 10iter: 8.1483 sec.\n",
      "반복 110 || Loss: 0.209027 || 10iter: 8.1365 sec.\n",
      "반복 120 || Loss: 0.145492 || 10iter: 8.8458 sec.\n",
      "반복 130 || Loss: 0.076361 || 10iter: 8.2547 sec.\n",
      "반복 140 || Loss: 0.069479 || 10iter: 8.1023 sec.\n",
      "반복 150 || Loss: 0.135678 || 10iter: 8.3065 sec.\n",
      "반복 160 || Loss: 0.131270 || 10iter: 8.2000 sec.\n",
      "반복 170 || Loss: 0.150835 || 10iter: 8.3389 sec.\n",
      "반복 180 || Loss: 0.279392 || 10iter: 8.0733 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:0.1790 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  171.5831 sec.\n",
      "-----------------------\n",
      "Epoch 2/5\n",
      "-----------------------\n",
      " (train) \n",
      "반복 190 || Loss: 0.065640 || 10iter: 5.4685 sec.\n",
      "반복 200 || Loss: 0.062947 || 10iter: 8.1495 sec.\n",
      "반복 210 || Loss: 0.086953 || 10iter: 8.1654 sec.\n",
      "반복 220 || Loss: 0.108796 || 10iter: 8.4409 sec.\n",
      "반복 230 || Loss: 0.080740 || 10iter: 8.1033 sec.\n",
      "반복 240 || Loss: 0.064764 || 10iter: 8.2123 sec.\n",
      "반복 250 || Loss: 0.093020 || 10iter: 8.1839 sec.\n",
      "반복 260 || Loss: 0.049842 || 10iter: 8.1285 sec.\n",
      "반복 270 || Loss: 0.091492 || 10iter: 8.1183 sec.\n",
      "반복 280 || Loss: 0.098007 || 10iter: 8.1133 sec.\n",
      "반복 290 || Loss: 0.061226 || 10iter: 8.0555 sec.\n",
      "반복 300 || Loss: 0.036862 || 10iter: 8.3389 sec.\n",
      "반복 310 || Loss: 0.138199 || 10iter: 8.2496 sec.\n",
      "반복 320 || Loss: 0.070404 || 10iter: 8.1997 sec.\n",
      "반복 330 || Loss: 0.141016 || 10iter: 8.6599 sec.\n",
      "반복 340 || Loss: 0.070373 || 10iter: 8.2517 sec.\n",
      "반복 350 || Loss: 0.078723 || 10iter: 8.3011 sec.\n",
      "반복 360 || Loss: 0.069698 || 10iter: 8.1029 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:0.0927 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  163.0055 sec.\n",
      "-----------------------\n",
      "Epoch 3/5\n",
      "-----------------------\n",
      " (train) \n",
      "반복 370 || Loss: 0.043178 || 10iter: 2.8696 sec.\n",
      "반복 380 || Loss: 0.051046 || 10iter: 8.3040 sec.\n",
      "반복 390 || Loss: 0.102457 || 10iter: 8.1459 sec.\n",
      "반복 400 || Loss: 0.064225 || 10iter: 8.2799 sec.\n",
      "반복 410 || Loss: 0.073121 || 10iter: 8.1789 sec.\n",
      "반복 420 || Loss: 0.073822 || 10iter: 8.1235 sec.\n",
      "반복 430 || Loss: 0.091650 || 10iter: 8.1256 sec.\n",
      "반복 440 || Loss: 0.052918 || 10iter: 8.1825 sec.\n",
      "반복 450 || Loss: 0.101576 || 10iter: 8.1008 sec.\n",
      "반복 460 || Loss: 0.047447 || 10iter: 8.0590 sec.\n",
      "반복 470 || Loss: 0.052578 || 10iter: 8.1563 sec.\n",
      "반복 480 || Loss: 0.075309 || 10iter: 8.1526 sec.\n",
      "반복 490 || Loss: 0.049510 || 10iter: 8.1023 sec.\n",
      "반복 500 || Loss: 0.078180 || 10iter: 8.0874 sec.\n",
      "반복 510 || Loss: 0.096064 || 10iter: 8.1948 sec.\n",
      "반복 520 || Loss: 0.191475 || 10iter: 8.0820 sec.\n",
      "반복 530 || Loss: 0.058899 || 10iter: 8.1968 sec.\n",
      "반복 540 || Loss: 0.039742 || 10iter: 8.0565 sec.\n",
      "-------------\n",
      "epoch 3 || Epoch_TRAIN_Loss:0.0811 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  161.7564 sec.\n",
      "-----------------------\n",
      "Epoch 4/5\n",
      "-----------------------\n",
      " (train) \n",
      "반복 550 || Loss: 0.094538 || 10iter: 0.1760 sec.\n",
      "반복 560 || Loss: 0.081317 || 10iter: 8.2998 sec.\n",
      "반복 570 || Loss: 0.055567 || 10iter: 8.2710 sec.\n",
      "반복 580 || Loss: 0.066206 || 10iter: 8.1858 sec.\n",
      "반복 590 || Loss: 0.168011 || 10iter: 8.0544 sec.\n",
      "반복 600 || Loss: 0.045489 || 10iter: 8.0693 sec.\n",
      "반복 610 || Loss: 0.065479 || 10iter: 8.2845 sec.\n",
      "반복 620 || Loss: 0.052777 || 10iter: 8.1829 sec.\n",
      "반복 630 || Loss: 0.089559 || 10iter: 8.0633 sec.\n",
      "반복 640 || Loss: 0.047036 || 10iter: 8.1152 sec.\n",
      "반복 650 || Loss: 0.080725 || 10iter: 8.2979 sec.\n",
      "반복 660 || Loss: 0.063931 || 10iter: 8.2079 sec.\n",
      "반복 670 || Loss: 0.085145 || 10iter: 8.1287 sec.\n",
      "반복 680 || Loss: 0.101045 || 10iter: 8.1396 sec.\n",
      "반복 690 || Loss: 0.075263 || 10iter: 8.0394 sec.\n",
      "반복 700 || Loss: 0.158045 || 10iter: 8.1835 sec.\n",
      "반복 710 || Loss: 0.044661 || 10iter: 8.1920 sec.\n",
      "반복 720 || Loss: 0.030425 || 10iter: 8.2373 sec.\n",
      "반복 730 || Loss: 0.077053 || 10iter: 8.1138 sec.\n",
      "-------------\n",
      "epoch 4 || Epoch_TRAIN_Loss:0.0715 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  162.2041 sec.\n",
      "-----------------------\n",
      "Epoch 5/5\n",
      "-----------------------\n",
      " (train) \n",
      "반복 740 || Loss: 0.055286 || 10iter: 6.3649 sec.\n",
      "반복 750 || Loss: 0.067507 || 10iter: 8.0580 sec.\n",
      "반복 760 || Loss: 0.110795 || 10iter: 8.1212 sec.\n",
      "반복 770 || Loss: 0.045714 || 10iter: 8.0520 sec.\n",
      "반복 780 || Loss: 0.044759 || 10iter: 8.0282 sec.\n",
      "반복 790 || Loss: 0.045800 || 10iter: 8.0015 sec.\n",
      "반복 800 || Loss: 0.083915 || 10iter: 7.9681 sec.\n",
      "반복 810 || Loss: 0.052488 || 10iter: 8.0006 sec.\n",
      "반복 820 || Loss: 0.099563 || 10iter: 7.9603 sec.\n",
      "반복 830 || Loss: 0.020322 || 10iter: 8.0517 sec.\n",
      "반복 840 || Loss: 0.068207 || 10iter: 8.0946 sec.\n",
      "반복 850 || Loss: 0.051090 || 10iter: 8.0879 sec.\n",
      "반복 860 || Loss: 0.066291 || 10iter: 8.0058 sec.\n",
      "반복 870 || Loss: 0.040309 || 10iter: 8.0659 sec.\n",
      "반복 880 || Loss: 0.060904 || 10iter: 8.0385 sec.\n",
      "반복 890 || Loss: 0.049185 || 10iter: 8.0245 sec.\n",
      "반복 900 || Loss: 0.053152 || 10iter: 8.1999 sec.\n",
      "반복 910 || Loss: 0.041925 || 10iter: 8.0072 sec.\n",
      "-----------------------\n",
      " (val) \n",
      "-------------\n",
      "epoch 5 || Epoch_TRAIN_Loss:0.0633 ||Epoch_VAL_Loss:0.0810\n",
      "timer:  214.5680 sec.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf2.5': conda)"
  },
  "interpreter": {
   "hash": "8713644ccf95bc94f9cdb73f3820952989f55b48f58b1b4cb3d9529941d252d1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}