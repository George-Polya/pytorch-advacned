{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os.path as osp\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 난수 시드 설정\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 로더 만들기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"사용 중인 장치:\", device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "사용 중인 장치: cuda:0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
    "\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
    "\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "color_mean = (104, 117, 123)  # (BGR) 색의 평균값\n",
    "input_size = 300  # 화상의 input 크기를 300×300으로 설정\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list,phase=\"val\",transform=DataTransform(input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn)\n",
    "\n",
    "dataloaders_dict = {\"train\":train_dataloader, \"val\":val_dataloader}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 네트워크 모델 만들기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from utils.ssd_model import SSD\n",
    "\n",
    "ssd_cfg = {\n",
    "    \"num_classes\" : 21,\n",
    "    \"input_size\":300,\n",
    "    \"bbox_aspect_num\":[4,6,6,6,4,4],\n",
    "    \"feature_maps\":[38,19,10,5,3,1],\n",
    "    \"steps\":[8,16,32,64,100,300],\n",
    "    \"min_sizes\":[30,60,111,162,213,264],\n",
    "    \"max_sizes\":[60,111,162,213,264,315],\n",
    "    \"aspect_ratios\" : [[2], [2,3], [2,3], [2,3], [2],[2]]\n",
    "}\n",
    "\n",
    "net = SSD(phase=\"train\", cfg=ssd_cfg)\n",
    "\n",
    "vgg_weights = torch.load(\"./weights/vgg16_reducedfc.pth\")\n",
    "net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "print(\"네트워크 설정 완료 : 학습된 가중치를 로드했습니다\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "네트워크 설정 완료 : 학습된 가중치를 로드했습니다\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 손실함수 및 최적화 기법 설정"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from utils.ssd_model import MultiBoxLoss\n",
    "\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 학습 및 검증 실시"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"사용중인 장치 : \", device)\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    logs = [ ]\n",
    "\n",
    "    for epoch in range(num_epochs+1):\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print(\"---------------------\")\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print(\"---------------------\")\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()\n",
    "                print(\"   ( train )   \")\n",
    "            else:\n",
    "                if((epoch+1)%10 == 0):\n",
    "                    net.eval()\n",
    "                    print(\"---------------------\")\n",
    "                    print(\"  ( val )  \")\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "                images = images.to(device)\n",
    "\n",
    "                targets = [ann.to(device) for ann in targets]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase==\"train\"):\n",
    "                    outputs = net(images)\n",
    "\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "                    \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "\n",
    "                        nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if iteration % 10 == 0:\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print(\"반복 {} || Loss: {:.4f} || 10iter: {:.4f}sec\".format(iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration+=1\n",
    "                    else:\n",
    "                        epoch_val_loss += loss\n",
    "\n",
    "        t_epoch_finish = time.time()\n",
    "        print(\"---------------------\")\n",
    "        print(\"epoch {} || Epoch_TRAIN_Loss:{:.4f} || Epoch_VAL_Loss:{:.4f}\".format(epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "        print(\"timer:  {:.4f} sec.\".format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        log_epoch = {\"epoch\":epoch+1, \"train_loss\":epoch_train_loss, \"val_loss\":epoch_val_loss}\n",
    "\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\", encoding=\"UTF-8\")\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            torch.save(net.state_dict(), \"weights/ssd300_\"+str(epoch+1)+\".pth\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "num_epochs = 50\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "사용중인 장치 :  cuda:0\n",
      "---------------------\n",
      "Epoch 1/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 10 || Loss: 15.9399 || 10iter: 13.2028sec\n",
      "반복 20 || Loss: 17.9391 || 10iter: 10.4726sec\n",
      "반복 30 || Loss: 11.7617 || 10iter: 9.7056sec\n",
      "반복 40 || Loss: 9.7139 || 10iter: 9.9039sec\n",
      "반복 50 || Loss: 9.4904 || 10iter: 11.2440sec\n",
      "반복 60 || Loss: 9.6938 || 10iter: 10.2189sec\n",
      "반복 70 || Loss: 8.4164 || 10iter: 10.3728sec\n",
      "반복 80 || Loss: 7.8673 || 10iter: 10.2731sec\n",
      "반복 90 || Loss: 8.4431 || 10iter: 10.5754sec\n",
      "반복 100 || Loss: 8.0078 || 10iter: 10.6629sec\n",
      "반복 110 || Loss: 8.4489 || 10iter: 10.6566sec\n",
      "반복 120 || Loss: 8.1499 || 10iter: 10.0580sec\n",
      "반복 130 || Loss: 7.6923 || 10iter: 10.7235sec\n",
      "반복 140 || Loss: 8.2139 || 10iter: 10.4391sec\n",
      "반복 150 || Loss: 7.3208 || 10iter: 9.5898sec\n",
      "반복 160 || Loss: 7.6584 || 10iter: 9.8669sec\n",
      "반복 170 || Loss: 7.1189 || 10iter: 10.4188sec\n",
      "---------------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:1701.8144 || Epoch_VAL_Loss:0.0000\n",
      "timer:  197.2518 sec.\n",
      "---------------------\n",
      "Epoch 2/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 180 || Loss: 7.1268 || 10iter: 0.6169sec\n",
      "반복 190 || Loss: 7.2260 || 10iter: 9.9507sec\n",
      "반복 200 || Loss: 7.8328 || 10iter: 10.1248sec\n",
      "반복 210 || Loss: 7.6698 || 10iter: 10.8884sec\n",
      "반복 220 || Loss: 7.4445 || 10iter: 9.6974sec\n",
      "반복 230 || Loss: 7.2869 || 10iter: 10.2488sec\n",
      "반복 240 || Loss: 7.2399 || 10iter: 9.4429sec\n",
      "반복 250 || Loss: 7.2315 || 10iter: 10.3605sec\n",
      "반복 260 || Loss: 7.1071 || 10iter: 10.0080sec\n",
      "반복 270 || Loss: 7.1755 || 10iter: 10.8602sec\n",
      "반복 280 || Loss: 7.3417 || 10iter: 9.9065sec\n",
      "반복 290 || Loss: 7.0228 || 10iter: 9.8616sec\n",
      "반복 300 || Loss: 7.0155 || 10iter: 9.7229sec\n",
      "반복 310 || Loss: 6.7256 || 10iter: 10.5842sec\n",
      "반복 320 || Loss: 6.7188 || 10iter: 10.2195sec\n",
      "반복 330 || Loss: 6.3935 || 10iter: 9.6831sec\n",
      "반복 340 || Loss: 7.3700 || 10iter: 10.5562sec\n",
      "반복 350 || Loss: 6.7397 || 10iter: 9.9534sec\n",
      "---------------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:1292.8802 || Epoch_VAL_Loss:0.0000\n",
      "timer:  183.9214 sec.\n",
      "---------------------\n",
      "Epoch 3/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 360 || Loss: 6.8797 || 10iter: 1.3548sec\n",
      "반복 370 || Loss: 7.7921 || 10iter: 9.8246sec\n",
      "반복 380 || Loss: 6.8397 || 10iter: 9.3613sec\n",
      "반복 390 || Loss: 6.7517 || 10iter: 10.0552sec\n",
      "반복 400 || Loss: 6.4993 || 10iter: 9.2490sec\n",
      "반복 410 || Loss: 7.1169 || 10iter: 10.5162sec\n",
      "반복 420 || Loss: 6.7679 || 10iter: 9.7197sec\n",
      "반복 430 || Loss: 6.6134 || 10iter: 9.7688sec\n",
      "반복 440 || Loss: 6.6953 || 10iter: 9.7742sec\n",
      "반복 450 || Loss: 6.7062 || 10iter: 9.7691sec\n",
      "반복 460 || Loss: 6.9864 || 10iter: 9.4508sec\n",
      "반복 470 || Loss: 6.5778 || 10iter: 9.9263sec\n",
      "반복 480 || Loss: 6.4486 || 10iter: 9.4668sec\n",
      "반복 490 || Loss: 6.4607 || 10iter: 9.6785sec\n",
      "반복 500 || Loss: 6.5877 || 10iter: 9.8913sec\n",
      "반복 510 || Loss: 6.7994 || 10iter: 9.2425sec\n",
      "반복 520 || Loss: 6.5145 || 10iter: 9.7107sec\n",
      "반복 530 || Loss: 6.7817 || 10iter: 10.4726sec\n",
      "---------------------\n",
      "epoch 3 || Epoch_TRAIN_Loss:1202.6050 || Epoch_VAL_Loss:0.0000\n",
      "timer:  178.9043 sec.\n",
      "---------------------\n",
      "Epoch 4/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 540 || Loss: 7.4316 || 10iter: 2.8223sec\n",
      "반복 550 || Loss: 6.5561 || 10iter: 9.8313sec\n",
      "반복 560 || Loss: 6.7749 || 10iter: 9.6597sec\n",
      "반복 570 || Loss: 6.6986 || 10iter: 9.6643sec\n",
      "반복 580 || Loss: 6.4024 || 10iter: 10.2207sec\n",
      "반복 590 || Loss: 6.7599 || 10iter: 9.7756sec\n",
      "반복 600 || Loss: 6.5346 || 10iter: 8.7300sec\n",
      "반복 610 || Loss: 6.4436 || 10iter: 10.1988sec\n",
      "반복 620 || Loss: 6.3436 || 10iter: 9.2991sec\n",
      "반복 630 || Loss: 6.9040 || 10iter: 10.3246sec\n",
      "반복 640 || Loss: 6.6761 || 10iter: 9.5857sec\n",
      "반복 650 || Loss: 5.6063 || 10iter: 9.6743sec\n",
      "반복 660 || Loss: 6.1748 || 10iter: 9.8561sec\n",
      "반복 670 || Loss: 5.9588 || 10iter: 9.1922sec\n",
      "반복 680 || Loss: 6.1281 || 10iter: 10.4792sec\n",
      "반복 690 || Loss: 6.4130 || 10iter: 9.4314sec\n",
      "반복 700 || Loss: 6.3586 || 10iter: 10.3973sec\n",
      "반복 710 || Loss: 6.3314 || 10iter: 9.6699sec\n",
      "---------------------\n",
      "epoch 4 || Epoch_TRAIN_Loss:1146.0708 || Epoch_VAL_Loss:0.0000\n",
      "timer:  179.1266 sec.\n",
      "---------------------\n",
      "Epoch 5/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 720 || Loss: 5.9982 || 10iter: 2.9386sec\n",
      "반복 730 || Loss: 6.2267 || 10iter: 9.7825sec\n",
      "반복 740 || Loss: 5.9549 || 10iter: 10.0369sec\n",
      "반복 750 || Loss: 6.2237 || 10iter: 10.2472sec\n",
      "반복 760 || Loss: 6.1802 || 10iter: 9.9843sec\n",
      "반복 770 || Loss: 6.0690 || 10iter: 9.3028sec\n",
      "반복 780 || Loss: 6.2574 || 10iter: 9.9831sec\n",
      "반복 790 || Loss: 5.9689 || 10iter: 9.4984sec\n",
      "반복 800 || Loss: 5.9480 || 10iter: 9.6283sec\n",
      "반복 810 || Loss: 5.9061 || 10iter: 9.9384sec\n",
      "반복 820 || Loss: 6.7102 || 10iter: 9.6038sec\n",
      "반복 830 || Loss: 5.8081 || 10iter: 9.9867sec\n",
      "반복 840 || Loss: 6.1853 || 10iter: 9.2980sec\n",
      "반복 850 || Loss: 6.4224 || 10iter: 10.0563sec\n",
      "반복 860 || Loss: 6.0773 || 10iter: 9.8909sec\n",
      "반복 870 || Loss: 5.9263 || 10iter: 9.9498sec\n",
      "반복 880 || Loss: 6.1164 || 10iter: 10.1598sec\n",
      "반복 890 || Loss: 5.8809 || 10iter: 9.8389sec\n",
      "---------------------\n",
      "epoch 5 || Epoch_TRAIN_Loss:1094.7806 || Epoch_VAL_Loss:0.0000\n",
      "timer:  179.6309 sec.\n",
      "---------------------\n",
      "Epoch 6/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 900 || Loss: 5.9861 || 10iter: 5.1669sec\n",
      "반복 910 || Loss: 6.1981 || 10iter: 9.4719sec\n",
      "반복 920 || Loss: 6.6550 || 10iter: 9.9037sec\n",
      "반복 930 || Loss: 6.1155 || 10iter: 10.4831sec\n",
      "반복 940 || Loss: 6.2819 || 10iter: 8.7814sec\n",
      "반복 950 || Loss: 6.5979 || 10iter: 9.2592sec\n",
      "반복 960 || Loss: 5.5166 || 10iter: 8.4739sec\n",
      "반복 970 || Loss: 6.2142 || 10iter: 10.4968sec\n",
      "반복 980 || Loss: 5.9727 || 10iter: 9.7067sec\n",
      "반복 990 || Loss: 5.4505 || 10iter: 9.9504sec\n",
      "반복 1000 || Loss: 5.9197 || 10iter: 9.5651sec\n",
      "반복 1010 || Loss: 5.4523 || 10iter: 10.3243sec\n",
      "반복 1020 || Loss: 5.6153 || 10iter: 9.4656sec\n",
      "반복 1030 || Loss: 5.8660 || 10iter: 9.1278sec\n",
      "반복 1040 || Loss: 6.0779 || 10iter: 10.1645sec\n",
      "반복 1050 || Loss: 6.2629 || 10iter: 9.6639sec\n",
      "반복 1060 || Loss: 6.0014 || 10iter: 9.9666sec\n",
      "반복 1070 || Loss: 6.0680 || 10iter: 10.0562sec\n",
      "---------------------\n",
      "epoch 6 || Epoch_TRAIN_Loss:1055.9119 || Epoch_VAL_Loss:0.0000\n",
      "timer:  178.7057 sec.\n",
      "---------------------\n",
      "Epoch 7/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 1080 || Loss: 6.0248 || 10iter: 6.0550sec\n",
      "반복 1090 || Loss: 5.6932 || 10iter: 8.9037sec\n",
      "반복 1100 || Loss: 5.8087 || 10iter: 9.5834sec\n",
      "반복 1110 || Loss: 5.3000 || 10iter: 10.0533sec\n",
      "반복 1120 || Loss: 5.8098 || 10iter: 9.6336sec\n",
      "반복 1130 || Loss: 5.8292 || 10iter: 9.5009sec\n",
      "반복 1140 || Loss: 6.0684 || 10iter: 10.0055sec\n",
      "반복 1150 || Loss: 5.8066 || 10iter: 8.6949sec\n",
      "반복 1160 || Loss: 5.6732 || 10iter: 11.3332sec\n",
      "반복 1170 || Loss: 5.8250 || 10iter: 10.1529sec\n",
      "반복 1180 || Loss: 5.9787 || 10iter: 10.4284sec\n",
      "반복 1190 || Loss: 5.5983 || 10iter: 9.6690sec\n",
      "반복 1200 || Loss: 5.5625 || 10iter: 9.2876sec\n",
      "반복 1210 || Loss: 5.8791 || 10iter: 9.4587sec\n",
      "반복 1220 || Loss: 6.2669 || 10iter: 10.2681sec\n",
      "반복 1230 || Loss: 5.3380 || 10iter: 10.7087sec\n",
      "반복 1240 || Loss: 5.8150 || 10iter: 10.6596sec\n",
      "반복 1250 || Loss: 5.8250 || 10iter: 10.0446sec\n",
      "---------------------\n",
      "epoch 7 || Epoch_TRAIN_Loss:1017.9503 || Epoch_VAL_Loss:0.0000\n",
      "timer:  182.4246 sec.\n",
      "---------------------\n",
      "Epoch 8/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 1260 || Loss: 5.5205 || 10iter: 6.6694sec\n",
      "반복 1270 || Loss: 5.4659 || 10iter: 10.8925sec\n",
      "반복 1280 || Loss: 5.7066 || 10iter: 9.9086sec\n",
      "반복 1290 || Loss: 5.4870 || 10iter: 9.8849sec\n",
      "반복 1300 || Loss: 5.3885 || 10iter: 9.2403sec\n",
      "반복 1310 || Loss: 5.8733 || 10iter: 9.8971sec\n",
      "반복 1320 || Loss: 5.3545 || 10iter: 9.5967sec\n",
      "반복 1330 || Loss: 5.9481 || 10iter: 9.6789sec\n",
      "반복 1340 || Loss: 5.7519 || 10iter: 11.1832sec\n",
      "반복 1350 || Loss: 5.4242 || 10iter: 8.9158sec\n",
      "반복 1360 || Loss: 5.6830 || 10iter: 10.7592sec\n",
      "반복 1370 || Loss: 5.5884 || 10iter: 9.6219sec\n",
      "반복 1380 || Loss: 5.7365 || 10iter: 9.8946sec\n",
      "반복 1390 || Loss: 5.7674 || 10iter: 9.7295sec\n",
      "반복 1400 || Loss: 5.4935 || 10iter: 9.8630sec\n",
      "반복 1410 || Loss: 5.4878 || 10iter: 10.8280sec\n",
      "반복 1420 || Loss: 5.2842 || 10iter: 9.4959sec\n",
      "반복 1430 || Loss: 5.1603 || 10iter: 9.6605sec\n",
      "---------------------\n",
      "epoch 8 || Epoch_TRAIN_Loss:983.7845 || Epoch_VAL_Loss:0.0000\n",
      "timer:  181.6133 sec.\n",
      "---------------------\n",
      "Epoch 9/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 1440 || Loss: 5.5474 || 10iter: 8.6315sec\n",
      "반복 1450 || Loss: 5.6357 || 10iter: 10.6326sec\n",
      "반복 1460 || Loss: 6.0611 || 10iter: 10.0273sec\n",
      "반복 1470 || Loss: 5.5991 || 10iter: 9.5770sec\n",
      "반복 1480 || Loss: 5.7541 || 10iter: 10.2574sec\n",
      "반복 1490 || Loss: 5.0435 || 10iter: 9.9113sec\n",
      "반복 1500 || Loss: 5.0865 || 10iter: 9.8298sec\n",
      "반복 1510 || Loss: 6.0688 || 10iter: 9.6201sec\n",
      "반복 1520 || Loss: 5.1506 || 10iter: 9.2013sec\n",
      "반복 1530 || Loss: 4.7367 || 10iter: 10.7389sec\n",
      "반복 1540 || Loss: 5.3837 || 10iter: 8.4602sec\n",
      "반복 1550 || Loss: 5.3785 || 10iter: 10.5448sec\n",
      "반복 1560 || Loss: 5.5860 || 10iter: 9.6063sec\n",
      "반복 1570 || Loss: 5.5735 || 10iter: 9.7789sec\n",
      "반복 1580 || Loss: 5.1281 || 10iter: 10.3050sec\n",
      "반복 1590 || Loss: 5.6203 || 10iter: 10.4083sec\n",
      "반복 1600 || Loss: 5.1447 || 10iter: 10.0096sec\n",
      "반복 1610 || Loss: 5.1445 || 10iter: 10.2171sec\n",
      "---------------------\n",
      "epoch 9 || Epoch_TRAIN_Loss:954.0453 || Epoch_VAL_Loss:0.0000\n",
      "timer:  183.8746 sec.\n",
      "---------------------\n",
      "Epoch 10/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 1620 || Loss: 5.5650 || 10iter: 8.8085sec\n",
      "반복 1630 || Loss: 4.8981 || 10iter: 10.2212sec\n",
      "반복 1640 || Loss: 4.7481 || 10iter: 10.7696sec\n",
      "반복 1650 || Loss: 5.3156 || 10iter: 9.8898sec\n",
      "반복 1660 || Loss: 5.1531 || 10iter: 10.9788sec\n",
      "반복 1670 || Loss: 5.2308 || 10iter: 10.4596sec\n",
      "반복 1680 || Loss: 5.0677 || 10iter: 10.3251sec\n",
      "반복 1690 || Loss: 5.8920 || 10iter: 10.0987sec\n",
      "반복 1700 || Loss: 5.1626 || 10iter: 10.4948sec\n",
      "반복 1710 || Loss: 4.6854 || 10iter: 10.9784sec\n",
      "반복 1720 || Loss: 5.3842 || 10iter: 9.8282sec\n",
      "반복 1730 || Loss: 5.6391 || 10iter: 10.2730sec\n",
      "반복 1740 || Loss: 5.1015 || 10iter: 9.7457sec\n",
      "반복 1750 || Loss: 5.3167 || 10iter: 10.5608sec\n",
      "반복 1760 || Loss: 5.8168 || 10iter: 10.8744sec\n",
      "반복 1770 || Loss: 5.4821 || 10iter: 9.6134sec\n",
      "반복 1780 || Loss: 5.2085 || 10iter: 10.4932sec\n",
      "반복 1790 || Loss: 5.7085 || 10iter: 9.2076sec\n",
      "---------------------\n",
      "  ( val )  \n",
      "---------------------\n",
      "epoch 10 || Epoch_TRAIN_Loss:939.0494 || Epoch_VAL_Loss:931.4612\n",
      "timer:  273.6521 sec.\n",
      "---------------------\n",
      "Epoch 11/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 1800 || Loss: 5.2009 || 10iter: 10.3286sec\n",
      "반복 1810 || Loss: 5.6745 || 10iter: 10.3263sec\n",
      "반복 1820 || Loss: 5.2795 || 10iter: 9.3883sec\n",
      "반복 1830 || Loss: 5.0573 || 10iter: 9.3185sec\n",
      "반복 1840 || Loss: 5.2987 || 10iter: 11.0934sec\n",
      "반복 1850 || Loss: 4.9583 || 10iter: 9.9728sec\n",
      "반복 1860 || Loss: 5.0633 || 10iter: 9.6857sec\n",
      "반복 1870 || Loss: 5.6784 || 10iter: 11.0591sec\n",
      "반복 1880 || Loss: 4.6090 || 10iter: 10.1662sec\n",
      "반복 1890 || Loss: 5.6483 || 10iter: 10.6077sec\n",
      "반복 1900 || Loss: 4.9880 || 10iter: 10.8423sec\n",
      "반복 1910 || Loss: 4.9092 || 10iter: 10.0426sec\n",
      "반복 1920 || Loss: 5.1063 || 10iter: 10.1468sec\n",
      "반복 1930 || Loss: 5.1337 || 10iter: 10.8569sec\n",
      "반복 1940 || Loss: 5.0170 || 10iter: 9.8389sec\n",
      "반복 1950 || Loss: 4.8627 || 10iter: 10.9119sec\n",
      "반복 1960 || Loss: 4.7934 || 10iter: 10.0535sec\n",
      "---------------------\n",
      "epoch 11 || Epoch_TRAIN_Loss:907.7384 || Epoch_VAL_Loss:0.0000\n",
      "timer:  188.9953 sec.\n",
      "---------------------\n",
      "Epoch 12/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 1970 || Loss: 5.3789 || 10iter: 0.6541sec\n",
      "반복 1980 || Loss: 5.1635 || 10iter: 9.5424sec\n",
      "반복 1990 || Loss: 4.9862 || 10iter: 9.7483sec\n",
      "반복 2000 || Loss: 4.8099 || 10iter: 9.8672sec\n",
      "반복 2010 || Loss: 5.5266 || 10iter: 10.3857sec\n",
      "반복 2020 || Loss: 4.4718 || 10iter: 10.0339sec\n",
      "반복 2030 || Loss: 4.7419 || 10iter: 10.2249sec\n",
      "반복 2040 || Loss: 5.3486 || 10iter: 10.9922sec\n",
      "반복 2050 || Loss: 4.6750 || 10iter: 10.1288sec\n",
      "반복 2060 || Loss: 4.6091 || 10iter: 9.6739sec\n",
      "반복 2070 || Loss: 5.4851 || 10iter: 11.1559sec\n",
      "반복 2080 || Loss: 5.0301 || 10iter: 10.2918sec\n",
      "반복 2090 || Loss: 4.7654 || 10iter: 10.0929sec\n",
      "반복 2100 || Loss: 5.1423 || 10iter: 10.6026sec\n",
      "반복 2110 || Loss: 5.2575 || 10iter: 10.0913sec\n",
      "반복 2120 || Loss: 4.9121 || 10iter: 9.4482sec\n",
      "반복 2130 || Loss: 4.9264 || 10iter: 10.1440sec\n",
      "반복 2140 || Loss: 4.9773 || 10iter: 10.8067sec\n",
      "---------------------\n",
      "epoch 12 || Epoch_TRAIN_Loss:887.4379 || Epoch_VAL_Loss:0.0000\n",
      "timer:  186.7809 sec.\n",
      "---------------------\n",
      "Epoch 13/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 2150 || Loss: 5.0720 || 10iter: 1.6111sec\n",
      "반복 2160 || Loss: 4.5585 || 10iter: 9.9521sec\n",
      "반복 2170 || Loss: 4.7976 || 10iter: 9.8028sec\n",
      "반복 2180 || Loss: 5.0002 || 10iter: 9.7269sec\n",
      "반복 2190 || Loss: 4.4048 || 10iter: 10.3056sec\n",
      "반복 2200 || Loss: 4.6238 || 10iter: 9.6982sec\n",
      "반복 2210 || Loss: 4.9696 || 10iter: 10.3878sec\n",
      "반복 2220 || Loss: 4.9006 || 10iter: 11.1884sec\n",
      "반복 2230 || Loss: 4.6629 || 10iter: 9.6589sec\n",
      "반복 2240 || Loss: 4.7566 || 10iter: 10.4617sec\n",
      "반복 2250 || Loss: 4.9312 || 10iter: 9.9612sec\n",
      "반복 2260 || Loss: 4.9704 || 10iter: 10.2127sec\n",
      "반복 2270 || Loss: 4.2534 || 10iter: 9.5096sec\n",
      "반복 2280 || Loss: 4.8274 || 10iter: 10.5169sec\n",
      "반복 2290 || Loss: 5.3689 || 10iter: 9.9600sec\n",
      "반복 2300 || Loss: 4.7517 || 10iter: 10.4410sec\n",
      "반복 2310 || Loss: 4.0227 || 10iter: 10.0256sec\n",
      "반복 2320 || Loss: 4.4692 || 10iter: 9.6960sec\n",
      "---------------------\n",
      "epoch 13 || Epoch_TRAIN_Loss:869.9815 || Epoch_VAL_Loss:0.0000\n",
      "timer:  185.0029 sec.\n",
      "---------------------\n",
      "Epoch 14/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 2330 || Loss: 4.0979 || 10iter: 2.8888sec\n",
      "반복 2340 || Loss: 4.8963 || 10iter: 9.4900sec\n",
      "반복 2350 || Loss: 4.9819 || 10iter: 10.1985sec\n",
      "반복 2360 || Loss: 4.4895 || 10iter: 9.7154sec\n",
      "반복 2370 || Loss: 5.1440 || 10iter: 10.2692sec\n",
      "반복 2380 || Loss: 5.0854 || 10iter: 10.4308sec\n",
      "반복 2390 || Loss: 5.3443 || 10iter: 9.6551sec\n",
      "반복 2400 || Loss: 4.6682 || 10iter: 10.6494sec\n",
      "반복 2410 || Loss: 4.9564 || 10iter: 10.1754sec\n",
      "반복 2420 || Loss: 4.7131 || 10iter: 9.6109sec\n",
      "반복 2430 || Loss: 5.0583 || 10iter: 10.2743sec\n",
      "반복 2440 || Loss: 4.6780 || 10iter: 10.7002sec\n",
      "반복 2450 || Loss: 4.4131 || 10iter: 9.7938sec\n",
      "반복 2460 || Loss: 4.4638 || 10iter: 10.3247sec\n",
      "반복 2470 || Loss: 4.7671 || 10iter: 9.8671sec\n",
      "반복 2480 || Loss: 4.8785 || 10iter: 10.8405sec\n",
      "반복 2490 || Loss: 5.2274 || 10iter: 9.5129sec\n",
      "반복 2500 || Loss: 4.8312 || 10iter: 9.8340sec\n",
      "---------------------\n",
      "epoch 14 || Epoch_TRAIN_Loss:854.1467 || Epoch_VAL_Loss:0.0000\n",
      "timer:  186.2890 sec.\n",
      "---------------------\n",
      "Epoch 15/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 2510 || Loss: 4.7502 || 10iter: 4.3706sec\n",
      "반복 2520 || Loss: 4.4579 || 10iter: 10.5920sec\n",
      "반복 2530 || Loss: 4.5799 || 10iter: 9.0790sec\n",
      "반복 2540 || Loss: 4.7273 || 10iter: 11.1790sec\n",
      "반복 2550 || Loss: 4.5720 || 10iter: 10.4331sec\n",
      "반복 2560 || Loss: 4.3633 || 10iter: 10.2461sec\n",
      "반복 2570 || Loss: 5.0731 || 10iter: 9.8651sec\n",
      "반복 2580 || Loss: 4.9984 || 10iter: 10.0821sec\n",
      "반복 2590 || Loss: 5.1033 || 10iter: 11.5116sec\n",
      "반복 2600 || Loss: 4.2186 || 10iter: 10.5924sec\n",
      "반복 2610 || Loss: 4.5686 || 10iter: 9.4432sec\n",
      "반복 2620 || Loss: 5.1676 || 10iter: 9.7762sec\n",
      "반복 2630 || Loss: 4.5081 || 10iter: 9.7087sec\n",
      "반복 2640 || Loss: 4.7453 || 10iter: 10.4940sec\n",
      "반복 2650 || Loss: 4.9237 || 10iter: 9.8265sec\n",
      "반복 2660 || Loss: 4.4569 || 10iter: 9.6784sec\n",
      "반복 2670 || Loss: 4.4163 || 10iter: 9.3336sec\n",
      "반복 2680 || Loss: 4.6867 || 10iter: 9.9009sec\n",
      "---------------------\n",
      "epoch 15 || Epoch_TRAIN_Loss:837.8201 || Epoch_VAL_Loss:0.0000\n",
      "timer:  186.6180 sec.\n",
      "---------------------\n",
      "Epoch 16/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 2690 || Loss: 4.7486 || 10iter: 4.9530sec\n",
      "반복 2700 || Loss: 4.5958 || 10iter: 9.4124sec\n",
      "반복 2710 || Loss: 4.8046 || 10iter: 10.0910sec\n",
      "반복 2720 || Loss: 4.2836 || 10iter: 10.5717sec\n",
      "반복 2730 || Loss: 4.7589 || 10iter: 10.5682sec\n",
      "반복 2740 || Loss: 4.4354 || 10iter: 10.1584sec\n",
      "반복 2750 || Loss: 4.7973 || 10iter: 10.4074sec\n",
      "반복 2760 || Loss: 4.5002 || 10iter: 10.3538sec\n",
      "반복 2770 || Loss: 4.7962 || 10iter: 9.9396sec\n",
      "반복 2780 || Loss: 5.0485 || 10iter: 9.5930sec\n",
      "반복 2790 || Loss: 4.8779 || 10iter: 10.6990sec\n",
      "반복 2800 || Loss: 4.2733 || 10iter: 9.8299sec\n",
      "반복 2810 || Loss: 4.5816 || 10iter: 9.8094sec\n",
      "반복 2820 || Loss: 5.0650 || 10iter: 10.3715sec\n",
      "반복 2830 || Loss: 4.8988 || 10iter: 10.2844sec\n",
      "반복 2840 || Loss: 4.2911 || 10iter: 9.7206sec\n",
      "반복 2850 || Loss: 4.8775 || 10iter: 9.5088sec\n",
      "반복 2860 || Loss: 5.0513 || 10iter: 10.0771sec\n",
      "---------------------\n",
      "epoch 16 || Epoch_TRAIN_Loss:823.1261 || Epoch_VAL_Loss:0.0000\n",
      "timer:  184.5995 sec.\n",
      "---------------------\n",
      "Epoch 17/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 2870 || Loss: 4.3009 || 10iter: 5.6245sec\n",
      "반복 2880 || Loss: 4.4272 || 10iter: 9.6301sec\n",
      "반복 2890 || Loss: 4.4066 || 10iter: 10.0587sec\n",
      "반복 2900 || Loss: 4.7487 || 10iter: 9.1294sec\n",
      "반복 2910 || Loss: 4.6404 || 10iter: 9.8246sec\n",
      "반복 2920 || Loss: 4.4622 || 10iter: 10.3026sec\n",
      "반복 2930 || Loss: 4.9834 || 10iter: 9.4267sec\n",
      "반복 2940 || Loss: 4.4951 || 10iter: 10.8737sec\n",
      "반복 2950 || Loss: 4.5092 || 10iter: 9.7858sec\n",
      "반복 2960 || Loss: 4.7740 || 10iter: 9.7545sec\n",
      "반복 2970 || Loss: 4.4502 || 10iter: 10.0816sec\n",
      "반복 2980 || Loss: 4.2162 || 10iter: 9.6894sec\n",
      "반복 2990 || Loss: 4.4183 || 10iter: 9.3316sec\n",
      "반복 3000 || Loss: 4.7989 || 10iter: 8.5714sec\n",
      "반복 3010 || Loss: 4.5023 || 10iter: 11.1355sec\n",
      "반복 3020 || Loss: 4.5609 || 10iter: 9.5977sec\n",
      "반복 3030 || Loss: 4.7571 || 10iter: 10.0559sec\n",
      "반복 3040 || Loss: 4.8444 || 10iter: 9.7843sec\n",
      "---------------------\n",
      "epoch 17 || Epoch_TRAIN_Loss:814.3108 || Epoch_VAL_Loss:0.0000\n",
      "timer:  180.3413 sec.\n",
      "---------------------\n",
      "Epoch 18/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 3050 || Loss: 4.8032 || 10iter: 6.5589sec\n",
      "반복 3060 || Loss: 3.8301 || 10iter: 10.0678sec\n",
      "반복 3070 || Loss: 4.7315 || 10iter: 9.7437sec\n",
      "반복 3080 || Loss: 4.1278 || 10iter: 10.1997sec\n",
      "반복 3090 || Loss: 5.1019 || 10iter: 10.0350sec\n",
      "반복 3100 || Loss: 4.7169 || 10iter: 9.9337sec\n",
      "반복 3110 || Loss: 4.0881 || 10iter: 10.0463sec\n",
      "반복 3120 || Loss: 4.7288 || 10iter: 9.5319sec\n",
      "반복 3130 || Loss: 4.6830 || 10iter: 8.9695sec\n",
      "반복 3140 || Loss: 4.5145 || 10iter: 10.2615sec\n",
      "반복 3150 || Loss: 4.7722 || 10iter: 9.5025sec\n",
      "반복 3160 || Loss: 4.3672 || 10iter: 9.4764sec\n",
      "반복 3170 || Loss: 4.4375 || 10iter: 9.4973sec\n",
      "반복 3180 || Loss: 4.8916 || 10iter: 9.7185sec\n",
      "반복 3190 || Loss: 4.1336 || 10iter: 10.7039sec\n",
      "반복 3200 || Loss: 4.3363 || 10iter: 9.1075sec\n",
      "반복 3210 || Loss: 4.7423 || 10iter: 10.2366sec\n",
      "반복 3220 || Loss: 4.2373 || 10iter: 10.2755sec\n",
      "---------------------\n",
      "epoch 18 || Epoch_TRAIN_Loss:795.8275 || Epoch_VAL_Loss:0.0000\n",
      "timer:  180.3776 sec.\n",
      "---------------------\n",
      "Epoch 19/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 3230 || Loss: 4.6273 || 10iter: 7.9605sec\n",
      "반복 3240 || Loss: 4.4070 || 10iter: 9.7506sec\n",
      "반복 3250 || Loss: 4.8780 || 10iter: 9.6343sec\n",
      "반복 3260 || Loss: 4.5584 || 10iter: 10.1847sec\n",
      "반복 3270 || Loss: 4.1932 || 10iter: 9.7716sec\n",
      "반복 3280 || Loss: 4.0317 || 10iter: 10.7204sec\n",
      "반복 3290 || Loss: 3.9813 || 10iter: 9.2689sec\n",
      "반복 3300 || Loss: 4.1257 || 10iter: 10.5559sec\n",
      "반복 3310 || Loss: 4.7352 || 10iter: 9.2201sec\n",
      "반복 3320 || Loss: 5.0913 || 10iter: 9.8469sec\n",
      "반복 3330 || Loss: 4.8857 || 10iter: 10.3852sec\n",
      "반복 3340 || Loss: 4.4981 || 10iter: 9.0457sec\n",
      "반복 3350 || Loss: 4.6277 || 10iter: 9.2071sec\n",
      "반복 3360 || Loss: 4.2732 || 10iter: 9.2702sec\n",
      "반복 3370 || Loss: 5.1924 || 10iter: 9.8866sec\n",
      "반복 3380 || Loss: 4.8318 || 10iter: 10.3452sec\n",
      "반복 3390 || Loss: 4.5518 || 10iter: 9.6464sec\n",
      "반복 3400 || Loss: 4.4814 || 10iter: 10.8624sec\n",
      "---------------------\n",
      "epoch 19 || Epoch_TRAIN_Loss:787.1064 || Epoch_VAL_Loss:0.0000\n",
      "timer:  181.0107 sec.\n",
      "---------------------\n",
      "Epoch 20/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 3410 || Loss: 4.2562 || 10iter: 8.6960sec\n",
      "반복 3420 || Loss: 4.4261 || 10iter: 10.0234sec\n",
      "반복 3430 || Loss: 4.1693 || 10iter: 10.1186sec\n",
      "반복 3440 || Loss: 4.2040 || 10iter: 9.4044sec\n",
      "반복 3450 || Loss: 4.3940 || 10iter: 9.9851sec\n",
      "반복 3460 || Loss: 3.9712 || 10iter: 10.3179sec\n",
      "반복 3470 || Loss: 4.3182 || 10iter: 10.0714sec\n",
      "반복 3480 || Loss: 4.7561 || 10iter: 9.7780sec\n",
      "반복 3490 || Loss: 4.2851 || 10iter: 10.2312sec\n",
      "반복 3500 || Loss: 4.2910 || 10iter: 9.8302sec\n",
      "반복 3510 || Loss: 4.6846 || 10iter: 10.3580sec\n",
      "반복 3520 || Loss: 4.1671 || 10iter: 10.0646sec\n",
      "반복 3530 || Loss: 4.2528 || 10iter: 10.4324sec\n",
      "반복 3540 || Loss: 4.0633 || 10iter: 9.8525sec\n",
      "반복 3550 || Loss: 5.0337 || 10iter: 9.8628sec\n",
      "반복 3560 || Loss: 4.1607 || 10iter: 9.7588sec\n",
      "반복 3570 || Loss: 4.4846 || 10iter: 9.8269sec\n",
      "반복 3580 || Loss: 4.3285 || 10iter: 10.1440sec\n",
      "---------------------\n",
      "  ( val )  \n",
      "---------------------\n",
      "epoch 20 || Epoch_TRAIN_Loss:772.5698 || Epoch_VAL_Loss:810.2753\n",
      "timer:  268.2280 sec.\n",
      "---------------------\n",
      "Epoch 21/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 3590 || Loss: 4.3983 || 10iter: 9.9731sec\n",
      "반복 3600 || Loss: 4.3074 || 10iter: 11.3693sec\n",
      "반복 3610 || Loss: 4.5745 || 10iter: 9.8737sec\n",
      "반복 3620 || Loss: 4.5007 || 10iter: 10.7998sec\n",
      "반복 3630 || Loss: 4.2498 || 10iter: 10.6434sec\n",
      "반복 3640 || Loss: 4.8179 || 10iter: 9.7649sec\n",
      "반복 3650 || Loss: 4.5494 || 10iter: 10.9432sec\n",
      "반복 3660 || Loss: 4.4232 || 10iter: 10.1047sec\n",
      "반복 3670 || Loss: 4.2560 || 10iter: 10.5621sec\n",
      "반복 3680 || Loss: 3.7901 || 10iter: 9.9158sec\n",
      "반복 3690 || Loss: 3.4485 || 10iter: 10.8797sec\n",
      "반복 3700 || Loss: 4.4659 || 10iter: 10.9728sec\n",
      "반복 3710 || Loss: 4.4779 || 10iter: 9.8687sec\n",
      "반복 3720 || Loss: 4.3059 || 10iter: 9.8375sec\n",
      "반복 3730 || Loss: 3.7344 || 10iter: 10.6626sec\n",
      "반복 3740 || Loss: 4.7788 || 10iter: 9.8630sec\n",
      "반복 3750 || Loss: 3.8444 || 10iter: 10.4466sec\n",
      "---------------------\n",
      "epoch 21 || Epoch_TRAIN_Loss:767.5423 || Epoch_VAL_Loss:0.0000\n",
      "timer:  190.8741 sec.\n",
      "---------------------\n",
      "Epoch 22/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 3760 || Loss: 4.5070 || 10iter: 0.7579sec\n",
      "반복 3770 || Loss: 4.5304 || 10iter: 10.1454sec\n",
      "반복 3780 || Loss: 4.4720 || 10iter: 10.4612sec\n",
      "반복 3790 || Loss: 4.2596 || 10iter: 9.8974sec\n",
      "반복 3800 || Loss: 3.7733 || 10iter: 10.6717sec\n",
      "반복 3810 || Loss: 4.6314 || 10iter: 10.0332sec\n",
      "반복 3820 || Loss: 4.5530 || 10iter: 10.0248sec\n",
      "반복 3830 || Loss: 3.9710 || 10iter: 10.1047sec\n",
      "반복 3840 || Loss: 4.4835 || 10iter: 10.1936sec\n",
      "반복 3850 || Loss: 4.1293 || 10iter: 9.2424sec\n",
      "반복 3860 || Loss: 4.0114 || 10iter: 9.0808sec\n",
      "반복 3870 || Loss: 3.9591 || 10iter: 11.6146sec\n",
      "반복 3880 || Loss: 4.5440 || 10iter: 9.6301sec\n",
      "반복 3890 || Loss: 4.1919 || 10iter: 10.2615sec\n",
      "반복 3900 || Loss: 3.9173 || 10iter: 10.5174sec\n",
      "반복 3910 || Loss: 4.0998 || 10iter: 9.8214sec\n",
      "반복 3920 || Loss: 4.0548 || 10iter: 10.5058sec\n",
      "반복 3930 || Loss: 4.1876 || 10iter: 10.0042sec\n",
      "---------------------\n",
      "epoch 22 || Epoch_TRAIN_Loss:753.4504 || Epoch_VAL_Loss:0.0000\n",
      "timer:  188.0256 sec.\n",
      "---------------------\n",
      "Epoch 23/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 3940 || Loss: 3.8664 || 10iter: 2.1471sec\n",
      "반복 3950 || Loss: 4.3295 || 10iter: 9.9372sec\n",
      "반복 3960 || Loss: 4.3255 || 10iter: 10.5090sec\n",
      "반복 3970 || Loss: 4.2036 || 10iter: 9.8751sec\n",
      "반복 3980 || Loss: 4.1537 || 10iter: 10.3024sec\n",
      "반복 3990 || Loss: 4.0050 || 10iter: 9.7962sec\n",
      "반복 4000 || Loss: 4.1986 || 10iter: 9.4092sec\n",
      "반복 4010 || Loss: 4.2298 || 10iter: 9.3316sec\n",
      "반복 4020 || Loss: 4.3141 || 10iter: 9.7947sec\n",
      "반복 4030 || Loss: 3.8031 || 10iter: 10.4266sec\n",
      "반복 4040 || Loss: 4.1427 || 10iter: 10.5682sec\n",
      "반복 4050 || Loss: 3.4976 || 10iter: 10.4195sec\n",
      "반복 4060 || Loss: 4.7684 || 10iter: 9.4408sec\n",
      "반복 4070 || Loss: 4.3081 || 10iter: 9.9548sec\n",
      "반복 4080 || Loss: 3.5971 || 10iter: 10.1779sec\n",
      "반복 4090 || Loss: 4.0207 || 10iter: 9.2934sec\n",
      "반복 4100 || Loss: 4.3923 || 10iter: 10.6189sec\n",
      "반복 4110 || Loss: 3.9785 || 10iter: 9.6796sec\n",
      "---------------------\n",
      "epoch 23 || Epoch_TRAIN_Loss:749.6723 || Epoch_VAL_Loss:0.0000\n",
      "timer:  183.6007 sec.\n",
      "---------------------\n",
      "Epoch 24/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 4120 || Loss: 4.1958 || 10iter: 3.3635sec\n",
      "반복 4130 || Loss: 4.1416 || 10iter: 9.8633sec\n",
      "반복 4140 || Loss: 4.2008 || 10iter: 10.5817sec\n",
      "반복 4150 || Loss: 3.5731 || 10iter: 10.7572sec\n",
      "반복 4160 || Loss: 4.6066 || 10iter: 10.3414sec\n",
      "반복 4170 || Loss: 4.8060 || 10iter: 10.2647sec\n",
      "반복 4180 || Loss: 4.1214 || 10iter: 9.8496sec\n",
      "반복 4190 || Loss: 4.1737 || 10iter: 11.1718sec\n",
      "반복 4200 || Loss: 3.9638 || 10iter: 10.4148sec\n",
      "반복 4210 || Loss: 4.2363 || 10iter: 8.6885sec\n",
      "반복 4220 || Loss: 4.0807 || 10iter: 11.4133sec\n",
      "반복 4230 || Loss: 3.4973 || 10iter: 10.4793sec\n",
      "반복 4240 || Loss: 4.2000 || 10iter: 10.1184sec\n",
      "반복 4250 || Loss: 4.0626 || 10iter: 10.0322sec\n",
      "반복 4260 || Loss: 3.7403 || 10iter: 9.3797sec\n",
      "반복 4270 || Loss: 4.3633 || 10iter: 9.4206sec\n",
      "반복 4280 || Loss: 3.8934 || 10iter: 10.5804sec\n",
      "반복 4290 || Loss: 3.6955 || 10iter: 9.9902sec\n",
      "---------------------\n",
      "epoch 24 || Epoch_TRAIN_Loss:731.4593 || Epoch_VAL_Loss:0.0000\n",
      "timer:  186.3839 sec.\n",
      "---------------------\n",
      "Epoch 25/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 4300 || Loss: 4.1698 || 10iter: 3.5360sec\n",
      "반복 4310 || Loss: 3.6467 || 10iter: 11.1153sec\n",
      "반복 4320 || Loss: 4.0612 || 10iter: 10.1550sec\n",
      "반복 4330 || Loss: 3.8658 || 10iter: 10.0085sec\n",
      "반복 4340 || Loss: 4.2589 || 10iter: 10.0922sec\n",
      "반복 4350 || Loss: 3.9572 || 10iter: 10.4268sec\n",
      "반복 4360 || Loss: 4.1976 || 10iter: 9.6699sec\n",
      "반복 4370 || Loss: 4.2716 || 10iter: 9.8160sec\n",
      "반복 4380 || Loss: 4.1417 || 10iter: 9.7578sec\n",
      "반복 4390 || Loss: 4.4087 || 10iter: 10.2168sec\n",
      "반복 4400 || Loss: 3.7137 || 10iter: 9.9248sec\n",
      "반복 4410 || Loss: 4.1460 || 10iter: 10.6004sec\n",
      "반복 4420 || Loss: 3.8909 || 10iter: 9.5416sec\n",
      "반복 4430 || Loss: 3.8133 || 10iter: 10.1913sec\n",
      "반복 4440 || Loss: 3.8935 || 10iter: 9.7599sec\n",
      "반복 4450 || Loss: 4.4875 || 10iter: 11.5046sec\n",
      "반복 4460 || Loss: 4.0980 || 10iter: 9.7773sec\n",
      "반복 4470 || Loss: 4.1021 || 10iter: 9.8862sec\n",
      "---------------------\n",
      "epoch 25 || Epoch_TRAIN_Loss:731.6698 || Epoch_VAL_Loss:0.0000\n",
      "timer:  186.4630 sec.\n",
      "---------------------\n",
      "Epoch 26/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 4480 || Loss: 4.4566 || 10iter: 5.0254sec\n",
      "반복 4490 || Loss: 4.1313 || 10iter: 10.2272sec\n",
      "반복 4500 || Loss: 4.1930 || 10iter: 10.3978sec\n",
      "반복 4510 || Loss: 3.7546 || 10iter: 9.2259sec\n",
      "반복 4520 || Loss: 3.7773 || 10iter: 10.3649sec\n",
      "반복 4530 || Loss: 4.2977 || 10iter: 9.9847sec\n",
      "반복 4540 || Loss: 4.3867 || 10iter: 10.8594sec\n",
      "반복 4550 || Loss: 3.8778 || 10iter: 9.7673sec\n",
      "반복 4560 || Loss: 4.3061 || 10iter: 10.1740sec\n",
      "반복 4570 || Loss: 3.7258 || 10iter: 10.1363sec\n",
      "반복 4580 || Loss: 3.6260 || 10iter: 10.3806sec\n",
      "반복 4590 || Loss: 4.3086 || 10iter: 10.1141sec\n",
      "반복 4600 || Loss: 4.3318 || 10iter: 10.0306sec\n",
      "반복 4610 || Loss: 4.0760 || 10iter: 10.3503sec\n",
      "반복 4620 || Loss: 3.9960 || 10iter: 9.6753sec\n",
      "반복 4630 || Loss: 3.6959 || 10iter: 10.8222sec\n",
      "반복 4640 || Loss: 3.7718 || 10iter: 10.9987sec\n",
      "반복 4650 || Loss: 4.3721 || 10iter: 9.8672sec\n",
      "---------------------\n",
      "epoch 26 || Epoch_TRAIN_Loss:723.1300 || Epoch_VAL_Loss:0.0000\n",
      "timer:  186.1692 sec.\n",
      "---------------------\n",
      "Epoch 27/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 4660 || Loss: 4.3273 || 10iter: 6.3556sec\n",
      "반복 4670 || Loss: 4.2454 || 10iter: 9.7729sec\n",
      "반복 4680 || Loss: 3.6263 || 10iter: 10.7063sec\n",
      "반복 4690 || Loss: 3.4952 || 10iter: 8.7299sec\n",
      "반복 4700 || Loss: 3.9959 || 10iter: 9.9814sec\n",
      "반복 4710 || Loss: 4.4315 || 10iter: 10.4473sec\n",
      "반복 4720 || Loss: 4.5049 || 10iter: 9.8154sec\n",
      "반복 4730 || Loss: 4.2202 || 10iter: 10.6908sec\n",
      "반복 4740 || Loss: 4.2090 || 10iter: 10.1835sec\n",
      "반복 4750 || Loss: 3.7199 || 10iter: 10.2646sec\n",
      "반복 4760 || Loss: 3.6584 || 10iter: 9.6448sec\n",
      "반복 4770 || Loss: 3.7724 || 10iter: 10.3926sec\n",
      "반복 4780 || Loss: 3.9720 || 10iter: 10.2921sec\n",
      "반복 4790 || Loss: 3.6797 || 10iter: 9.7023sec\n",
      "반복 4800 || Loss: 3.8870 || 10iter: 10.1353sec\n",
      "반복 4810 || Loss: 4.5246 || 10iter: 10.2052sec\n",
      "반복 4820 || Loss: 3.8655 || 10iter: 9.9158sec\n",
      "반복 4830 || Loss: 3.6147 || 10iter: 10.5264sec\n",
      "---------------------\n",
      "epoch 27 || Epoch_TRAIN_Loss:714.9064 || Epoch_VAL_Loss:0.0000\n",
      "timer:  185.4785 sec.\n",
      "---------------------\n",
      "Epoch 28/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 4840 || Loss: 4.4522 || 10iter: 7.5729sec\n",
      "반복 4850 || Loss: 3.4155 || 10iter: 9.9281sec\n",
      "반복 4860 || Loss: 3.9444 || 10iter: 9.3897sec\n",
      "반복 4870 || Loss: 3.3821 || 10iter: 10.8895sec\n",
      "반복 4880 || Loss: 4.0767 || 10iter: 10.2503sec\n",
      "반복 4890 || Loss: 4.3170 || 10iter: 9.9649sec\n",
      "반복 4900 || Loss: 3.9738 || 10iter: 9.5392sec\n",
      "반복 4910 || Loss: 3.3794 || 10iter: 9.8084sec\n",
      "반복 4920 || Loss: 3.7827 || 10iter: 11.2756sec\n",
      "반복 4930 || Loss: 3.7889 || 10iter: 10.1572sec\n",
      "반복 4940 || Loss: 3.5628 || 10iter: 10.0820sec\n",
      "반복 4950 || Loss: 4.5371 || 10iter: 9.6616sec\n",
      "반복 4960 || Loss: 3.8070 || 10iter: 9.4726sec\n",
      "반복 4970 || Loss: 3.8318 || 10iter: 9.8752sec\n",
      "반복 4980 || Loss: 4.0225 || 10iter: 9.3524sec\n",
      "반복 4990 || Loss: 4.4455 || 10iter: 10.3333sec\n",
      "반복 5000 || Loss: 3.5240 || 10iter: 10.9903sec\n",
      "반복 5010 || Loss: 4.0963 || 10iter: 9.6281sec\n",
      "---------------------\n",
      "epoch 28 || Epoch_TRAIN_Loss:708.0174 || Epoch_VAL_Loss:0.0000\n",
      "timer:  184.6323 sec.\n",
      "---------------------\n",
      "Epoch 29/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 5020 || Loss: 3.8686 || 10iter: 8.7945sec\n",
      "반복 5030 || Loss: 3.9148 || 10iter: 9.7600sec\n",
      "반복 5040 || Loss: 3.9386 || 10iter: 10.5339sec\n",
      "반복 5050 || Loss: 3.7444 || 10iter: 10.5401sec\n",
      "반복 5060 || Loss: 3.8872 || 10iter: 8.9463sec\n",
      "반복 5070 || Loss: 3.6302 || 10iter: 11.6510sec\n",
      "반복 5080 || Loss: 3.2245 || 10iter: 9.9626sec\n",
      "반복 5090 || Loss: 3.8650 || 10iter: 10.7278sec\n",
      "반복 5100 || Loss: 3.5739 || 10iter: 10.0624sec\n",
      "반복 5110 || Loss: 4.2140 || 10iter: 10.8859sec\n",
      "반복 5120 || Loss: 3.7420 || 10iter: 9.7252sec\n",
      "반복 5130 || Loss: 3.8978 || 10iter: 10.2410sec\n",
      "반복 5140 || Loss: 3.9056 || 10iter: 9.5175sec\n",
      "반복 5150 || Loss: 3.3145 || 10iter: 8.3028sec\n",
      "반복 5160 || Loss: 3.8045 || 10iter: 11.4278sec\n",
      "반복 5170 || Loss: 3.7497 || 10iter: 9.6247sec\n",
      "반복 5180 || Loss: 4.2986 || 10iter: 10.1523sec\n",
      "반복 5190 || Loss: 3.9859 || 10iter: 10.0757sec\n",
      "---------------------\n",
      "epoch 29 || Epoch_TRAIN_Loss:699.7136 || Epoch_VAL_Loss:0.0000\n",
      "timer:  187.1432 sec.\n",
      "---------------------\n",
      "Epoch 30/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 5200 || Loss: 3.7076 || 10iter: 9.7766sec\n",
      "반복 5210 || Loss: 4.2300 || 10iter: 10.0191sec\n",
      "반복 5220 || Loss: 3.6865 || 10iter: 9.9432sec\n",
      "반복 5230 || Loss: 3.5494 || 10iter: 10.2674sec\n",
      "반복 5240 || Loss: 3.9631 || 10iter: 9.5669sec\n",
      "반복 5250 || Loss: 3.7774 || 10iter: 10.4538sec\n",
      "반복 5260 || Loss: 4.1995 || 10iter: 10.2584sec\n",
      "반복 5270 || Loss: 4.1581 || 10iter: 9.9833sec\n",
      "반복 5280 || Loss: 3.7518 || 10iter: 10.0747sec\n",
      "반복 5290 || Loss: 4.0738 || 10iter: 9.7292sec\n",
      "반복 5300 || Loss: 3.8764 || 10iter: 10.9599sec\n",
      "반복 5310 || Loss: 3.9907 || 10iter: 9.5845sec\n",
      "반복 5320 || Loss: 3.5291 || 10iter: 10.8203sec\n",
      "반복 5330 || Loss: 3.9251 || 10iter: 8.9528sec\n",
      "반복 5340 || Loss: 3.7498 || 10iter: 9.4821sec\n",
      "반복 5350 || Loss: 3.9123 || 10iter: 10.0993sec\n",
      "반복 5360 || Loss: 3.9315 || 10iter: 9.5655sec\n",
      "반복 5370 || Loss: 3.8088 || 10iter: 9.4250sec\n",
      "---------------------\n",
      "  ( val )  \n",
      "---------------------\n",
      "epoch 30 || Epoch_TRAIN_Loss:700.5677 || Epoch_VAL_Loss:733.5109\n",
      "timer:  267.1108 sec.\n",
      "---------------------\n",
      "Epoch 31/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 5380 || Loss: 3.8460 || 10iter: 9.6964sec\n",
      "반복 5390 || Loss: 3.6422 || 10iter: 9.7616sec\n",
      "반복 5400 || Loss: 3.9136 || 10iter: 10.1455sec\n",
      "반복 5410 || Loss: 3.8598 || 10iter: 9.9407sec\n",
      "반복 5420 || Loss: 4.1915 || 10iter: 10.4123sec\n",
      "반복 5430 || Loss: 3.8851 || 10iter: 10.9602sec\n",
      "반복 5440 || Loss: 3.6306 || 10iter: 10.6676sec\n",
      "반복 5450 || Loss: 3.8654 || 10iter: 10.4160sec\n",
      "반복 5460 || Loss: 3.6138 || 10iter: 9.8758sec\n",
      "반복 5470 || Loss: 4.3074 || 10iter: 10.0480sec\n",
      "반복 5480 || Loss: 4.0557 || 10iter: 10.3914sec\n",
      "반복 5490 || Loss: 4.0022 || 10iter: 9.8697sec\n",
      "반복 5500 || Loss: 3.8348 || 10iter: 9.7729sec\n",
      "반복 5510 || Loss: 3.7291 || 10iter: 11.2882sec\n",
      "반복 5520 || Loss: 3.5492 || 10iter: 9.7845sec\n",
      "반복 5530 || Loss: 3.5602 || 10iter: 9.8944sec\n",
      "반복 5540 || Loss: 3.7557 || 10iter: 9.8267sec\n",
      "---------------------\n",
      "epoch 31 || Epoch_TRAIN_Loss:683.0370 || Epoch_VAL_Loss:0.0000\n",
      "timer:  185.8378 sec.\n",
      "---------------------\n",
      "Epoch 32/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 5550 || Loss: 3.8170 || 10iter: 0.6880sec\n",
      "반복 5560 || Loss: 3.5510 || 10iter: 10.2839sec\n",
      "반복 5570 || Loss: 3.7801 || 10iter: 9.5696sec\n",
      "반복 5580 || Loss: 4.0876 || 10iter: 10.0963sec\n",
      "반복 5590 || Loss: 3.5045 || 10iter: 9.6531sec\n",
      "반복 5600 || Loss: 3.6136 || 10iter: 10.7420sec\n",
      "반복 5610 || Loss: 3.9195 || 10iter: 9.6392sec\n",
      "반복 5620 || Loss: 3.8421 || 10iter: 10.5660sec\n",
      "반복 5630 || Loss: 3.8514 || 10iter: 9.7553sec\n",
      "반복 5640 || Loss: 3.8102 || 10iter: 10.9176sec\n",
      "반복 5650 || Loss: 3.6337 || 10iter: 9.7481sec\n",
      "반복 5660 || Loss: 4.0068 || 10iter: 9.6350sec\n",
      "반복 5670 || Loss: 3.5851 || 10iter: 10.8996sec\n",
      "반복 5680 || Loss: 3.8810 || 10iter: 10.3270sec\n",
      "반복 5690 || Loss: 3.3737 || 10iter: 10.3213sec\n",
      "반복 5700 || Loss: 3.8732 || 10iter: 9.5180sec\n",
      "반복 5710 || Loss: 3.4854 || 10iter: 9.4463sec\n",
      "반복 5720 || Loss: 4.1490 || 10iter: 9.7317sec\n",
      "---------------------\n",
      "epoch 32 || Epoch_TRAIN_Loss:675.7342 || Epoch_VAL_Loss:0.0000\n",
      "timer:  185.9524 sec.\n",
      "---------------------\n",
      "Epoch 33/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 5730 || Loss: 4.2717 || 10iter: 1.6705sec\n",
      "반복 5740 || Loss: 3.8300 || 10iter: 9.0554sec\n",
      "반복 5750 || Loss: 3.4767 || 10iter: 10.2111sec\n",
      "반복 5760 || Loss: 3.5777 || 10iter: 10.5753sec\n",
      "반복 5770 || Loss: 4.3336 || 10iter: 9.8097sec\n",
      "반복 5780 || Loss: 3.4940 || 10iter: 10.7320sec\n",
      "반복 5790 || Loss: 3.7605 || 10iter: 10.5334sec\n",
      "반복 5800 || Loss: 3.8791 || 10iter: 9.1078sec\n",
      "반복 5810 || Loss: 3.5770 || 10iter: 10.9171sec\n",
      "반복 5820 || Loss: 3.7207 || 10iter: 10.5700sec\n",
      "반복 5830 || Loss: 3.3332 || 10iter: 10.3131sec\n",
      "반복 5840 || Loss: 4.2200 || 10iter: 10.0884sec\n",
      "반복 5850 || Loss: 3.4572 || 10iter: 9.5037sec\n",
      "반복 5860 || Loss: 4.0142 || 10iter: 9.7314sec\n",
      "반복 5870 || Loss: 4.1032 || 10iter: 10.5494sec\n",
      "반복 5880 || Loss: 3.7728 || 10iter: 9.9164sec\n",
      "반복 5890 || Loss: 3.6911 || 10iter: 10.9002sec\n",
      "반복 5900 || Loss: 3.7564 || 10iter: 10.4621sec\n",
      "---------------------\n",
      "epoch 33 || Epoch_TRAIN_Loss:677.4976 || Epoch_VAL_Loss:0.0000\n",
      "timer:  187.0280 sec.\n",
      "---------------------\n",
      "Epoch 34/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 5910 || Loss: 3.6476 || 10iter: 2.6805sec\n",
      "반복 5920 || Loss: 4.0515 || 10iter: 9.5169sec\n",
      "반복 5930 || Loss: 3.8401 || 10iter: 10.8854sec\n",
      "반복 5940 || Loss: 3.6875 || 10iter: 9.7682sec\n",
      "반복 5950 || Loss: 3.6925 || 10iter: 11.0210sec\n",
      "반복 5960 || Loss: 3.7790 || 10iter: 10.8534sec\n",
      "반복 5970 || Loss: 3.9548 || 10iter: 9.7400sec\n",
      "반복 5980 || Loss: 3.9877 || 10iter: 9.1590sec\n",
      "반복 5990 || Loss: 3.7749 || 10iter: 11.3718sec\n",
      "반복 6000 || Loss: 4.2181 || 10iter: 10.5843sec\n",
      "반복 6010 || Loss: 3.8595 || 10iter: 10.8359sec\n",
      "반복 6020 || Loss: 4.1176 || 10iter: 10.1606sec\n",
      "반복 6030 || Loss: 4.1476 || 10iter: 9.7788sec\n",
      "반복 6040 || Loss: 3.0498 || 10iter: 9.5338sec\n",
      "반복 6050 || Loss: 3.4365 || 10iter: 10.7760sec\n",
      "반복 6060 || Loss: 3.3569 || 10iter: 10.5082sec\n",
      "반복 6070 || Loss: 3.8057 || 10iter: 8.5469sec\n",
      "반복 6080 || Loss: 3.8603 || 10iter: 12.0912sec\n",
      "---------------------\n",
      "epoch 34 || Epoch_TRAIN_Loss:674.8025 || Epoch_VAL_Loss:0.0000\n",
      "timer:  187.2179 sec.\n",
      "---------------------\n",
      "Epoch 35/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 6090 || Loss: 4.0468 || 10iter: 4.2971sec\n",
      "반복 6100 || Loss: 3.9278 || 10iter: 10.0064sec\n",
      "반복 6110 || Loss: 4.0654 || 10iter: 9.8141sec\n",
      "반복 6120 || Loss: 3.4331 || 10iter: 9.5457sec\n",
      "반복 6130 || Loss: 3.3575 || 10iter: 9.8706sec\n",
      "반복 6140 || Loss: 3.3835 || 10iter: 10.5821sec\n",
      "반복 6150 || Loss: 2.9729 || 10iter: 10.6020sec\n",
      "반복 6160 || Loss: 3.9146 || 10iter: 10.6853sec\n",
      "반복 6170 || Loss: 3.5009 || 10iter: 9.5259sec\n",
      "반복 6180 || Loss: 3.5267 || 10iter: 9.8576sec\n",
      "반복 6190 || Loss: 3.4589 || 10iter: 9.9887sec\n",
      "반복 6200 || Loss: 4.0275 || 10iter: 10.4949sec\n",
      "반복 6210 || Loss: 4.0326 || 10iter: 10.4882sec\n",
      "반복 6220 || Loss: 3.4835 || 10iter: 10.5048sec\n",
      "반복 6230 || Loss: 3.2648 || 10iter: 10.2003sec\n",
      "반복 6240 || Loss: 4.1299 || 10iter: 10.1802sec\n",
      "반복 6250 || Loss: 3.7178 || 10iter: 10.9192sec\n",
      "반복 6260 || Loss: 3.8095 || 10iter: 9.6062sec\n",
      "---------------------\n",
      "epoch 35 || Epoch_TRAIN_Loss:664.7948 || Epoch_VAL_Loss:0.0000\n",
      "timer:  186.4499 sec.\n",
      "---------------------\n",
      "Epoch 36/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 6270 || Loss: 3.4192 || 10iter: 4.7384sec\n",
      "반복 6280 || Loss: 3.9270 || 10iter: 9.7454sec\n",
      "반복 6290 || Loss: 3.5406 || 10iter: 9.6123sec\n",
      "반복 6300 || Loss: 3.9113 || 10iter: 10.0543sec\n",
      "반복 6310 || Loss: 3.9678 || 10iter: 9.6530sec\n",
      "반복 6320 || Loss: 3.7193 || 10iter: 10.4616sec\n",
      "반복 6330 || Loss: 3.5478 || 10iter: 10.4029sec\n",
      "반복 6340 || Loss: 3.3406 || 10iter: 9.4437sec\n",
      "반복 6350 || Loss: 3.8086 || 10iter: 9.5285sec\n",
      "반복 6360 || Loss: 4.2534 || 10iter: 9.8067sec\n",
      "반복 6370 || Loss: 3.5434 || 10iter: 9.4663sec\n",
      "반복 6380 || Loss: 3.4277 || 10iter: 10.5916sec\n",
      "반복 6390 || Loss: 4.1069 || 10iter: 10.3298sec\n",
      "반복 6400 || Loss: 3.8403 || 10iter: 9.8676sec\n",
      "반복 6410 || Loss: 3.3554 || 10iter: 11.2867sec\n",
      "반복 6420 || Loss: 3.9329 || 10iter: 10.4642sec\n",
      "반복 6430 || Loss: 3.7395 || 10iter: 10.4244sec\n",
      "반복 6440 || Loss: 3.6081 || 10iter: 9.9055sec\n",
      "---------------------\n",
      "epoch 36 || Epoch_TRAIN_Loss:660.7284 || Epoch_VAL_Loss:0.0000\n",
      "timer:  186.1140 sec.\n",
      "---------------------\n",
      "Epoch 37/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 6450 || Loss: 3.4298 || 10iter: 5.1808sec\n",
      "반복 6460 || Loss: 3.8151 || 10iter: 9.7955sec\n",
      "반복 6470 || Loss: 3.7094 || 10iter: 9.5525sec\n",
      "반복 6480 || Loss: 3.4514 || 10iter: 9.9318sec\n",
      "반복 6490 || Loss: 3.9920 || 10iter: 9.8433sec\n",
      "반복 6500 || Loss: 3.7151 || 10iter: 9.4697sec\n",
      "반복 6510 || Loss: 3.7478 || 10iter: 10.8003sec\n",
      "반복 6520 || Loss: 3.5463 || 10iter: 9.9286sec\n",
      "반복 6530 || Loss: 3.4570 || 10iter: 10.3439sec\n",
      "반복 6540 || Loss: 3.6337 || 10iter: 9.9013sec\n",
      "반복 6550 || Loss: 3.9746 || 10iter: 10.2417sec\n",
      "반복 6560 || Loss: 3.6700 || 10iter: 10.2895sec\n",
      "반복 6570 || Loss: 3.9431 || 10iter: 10.0124sec\n",
      "반복 6580 || Loss: 3.7760 || 10iter: 9.9065sec\n",
      "반복 6590 || Loss: 3.9601 || 10iter: 9.7871sec\n",
      "반복 6600 || Loss: 3.8340 || 10iter: 9.4167sec\n",
      "반복 6610 || Loss: 3.7621 || 10iter: 10.9032sec\n",
      "반복 6620 || Loss: 3.7419 || 10iter: 9.7455sec\n",
      "---------------------\n",
      "epoch 37 || Epoch_TRAIN_Loss:653.4768 || Epoch_VAL_Loss:0.0000\n",
      "timer:  183.5754 sec.\n",
      "---------------------\n",
      "Epoch 38/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 6630 || Loss: 3.0181 || 10iter: 7.1260sec\n",
      "반복 6640 || Loss: 3.4293 || 10iter: 10.1527sec\n",
      "반복 6650 || Loss: 2.9770 || 10iter: 9.9513sec\n",
      "반복 6660 || Loss: 3.7848 || 10iter: 9.6089sec\n",
      "반복 6670 || Loss: 3.6578 || 10iter: 10.4226sec\n",
      "반복 6680 || Loss: 3.8457 || 10iter: 9.9769sec\n",
      "반복 6690 || Loss: 3.4480 || 10iter: 10.0752sec\n",
      "반복 6700 || Loss: 4.0067 || 10iter: 11.0768sec\n",
      "반복 6710 || Loss: 3.2837 || 10iter: 10.0100sec\n",
      "반복 6720 || Loss: 3.5322 || 10iter: 9.9086sec\n",
      "반복 6730 || Loss: 3.8160 || 10iter: 11.3704sec\n",
      "반복 6740 || Loss: 3.4122 || 10iter: 9.8069sec\n",
      "반복 6750 || Loss: 3.4264 || 10iter: 11.0129sec\n",
      "반복 6760 || Loss: 3.9506 || 10iter: 9.6807sec\n",
      "반복 6770 || Loss: 3.4967 || 10iter: 9.8332sec\n",
      "반복 6780 || Loss: 3.3641 || 10iter: 11.1513sec\n",
      "반복 6790 || Loss: 3.2848 || 10iter: 9.5703sec\n",
      "반복 6800 || Loss: 3.6719 || 10iter: 10.2418sec\n",
      "---------------------\n",
      "epoch 38 || Epoch_TRAIN_Loss:648.0560 || Epoch_VAL_Loss:0.0000\n",
      "timer:  187.7349 sec.\n",
      "---------------------\n",
      "Epoch 39/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 6810 || Loss: 3.6847 || 10iter: 7.6268sec\n",
      "반복 6820 || Loss: 3.6525 || 10iter: 9.8488sec\n",
      "반복 6830 || Loss: 3.8021 || 10iter: 9.9163sec\n",
      "반복 6840 || Loss: 3.7158 || 10iter: 9.5725sec\n",
      "반복 6850 || Loss: 4.0299 || 10iter: 10.4507sec\n",
      "반복 6860 || Loss: 3.2599 || 10iter: 10.2807sec\n",
      "반복 6870 || Loss: 3.9500 || 10iter: 10.1839sec\n",
      "반복 6880 || Loss: 3.0873 || 10iter: 10.3593sec\n",
      "반복 6890 || Loss: 4.2264 || 10iter: 9.7757sec\n",
      "반복 6900 || Loss: 3.0697 || 10iter: 10.2132sec\n",
      "반복 6910 || Loss: 3.0335 || 10iter: 9.6168sec\n",
      "반복 6920 || Loss: 3.5784 || 10iter: 10.7320sec\n",
      "반복 6930 || Loss: 3.5679 || 10iter: 9.7697sec\n",
      "반복 6940 || Loss: 3.8443 || 10iter: 11.0440sec\n",
      "반복 6950 || Loss: 3.6265 || 10iter: 9.8667sec\n",
      "반복 6960 || Loss: 3.4811 || 10iter: 9.7036sec\n",
      "반복 6970 || Loss: 3.1327 || 10iter: 10.9741sec\n",
      "반복 6980 || Loss: 4.0256 || 10iter: 9.9991sec\n",
      "---------------------\n",
      "epoch 39 || Epoch_TRAIN_Loss:641.5909 || Epoch_VAL_Loss:0.0000\n",
      "timer:  185.1079 sec.\n",
      "---------------------\n",
      "Epoch 40/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 6990 || Loss: 3.9245 || 10iter: 9.2741sec\n",
      "반복 7000 || Loss: 3.9428 || 10iter: 10.0418sec\n",
      "반복 7010 || Loss: 3.8162 || 10iter: 10.8910sec\n",
      "반복 7020 || Loss: 3.5806 || 10iter: 9.9155sec\n",
      "반복 7030 || Loss: 3.3164 || 10iter: 9.6356sec\n",
      "반복 7040 || Loss: 3.5616 || 10iter: 10.6318sec\n",
      "반복 7050 || Loss: 3.2811 || 10iter: 9.2242sec\n",
      "반복 7060 || Loss: 3.2867 || 10iter: 10.4263sec\n",
      "반복 7070 || Loss: 3.4034 || 10iter: 9.5731sec\n",
      "반복 7080 || Loss: 3.4958 || 10iter: 9.4393sec\n",
      "반복 7090 || Loss: 3.4275 || 10iter: 11.0502sec\n",
      "반복 7100 || Loss: 3.8594 || 10iter: 10.9387sec\n",
      "반복 7110 || Loss: 3.7625 || 10iter: 10.3813sec\n",
      "반복 7120 || Loss: 3.2996 || 10iter: 10.4196sec\n",
      "반복 7130 || Loss: 3.0520 || 10iter: 10.0242sec\n",
      "반복 7140 || Loss: 3.1755 || 10iter: 10.4355sec\n",
      "반복 7150 || Loss: 3.2485 || 10iter: 9.3489sec\n",
      "반복 7160 || Loss: 3.7889 || 10iter: 8.8605sec\n",
      "---------------------\n",
      "  ( val )  \n",
      "---------------------\n",
      "epoch 40 || Epoch_TRAIN_Loss:643.6799 || Epoch_VAL_Loss:699.1010\n",
      "timer:  267.9541 sec.\n",
      "---------------------\n",
      "Epoch 41/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 7170 || Loss: 3.9190 || 10iter: 9.1237sec\n",
      "반복 7180 || Loss: 3.6080 || 10iter: 10.5100sec\n",
      "반복 7190 || Loss: 3.4220 || 10iter: 9.3951sec\n",
      "반복 7200 || Loss: 3.5298 || 10iter: 11.0900sec\n",
      "반복 7210 || Loss: 3.5940 || 10iter: 9.0600sec\n",
      "반복 7220 || Loss: 3.7994 || 10iter: 10.9971sec\n",
      "반복 7230 || Loss: 3.5373 || 10iter: 10.2971sec\n",
      "반복 7240 || Loss: 3.4818 || 10iter: 9.2843sec\n",
      "반복 7250 || Loss: 3.2138 || 10iter: 9.4356sec\n",
      "반복 7260 || Loss: 3.8260 || 10iter: 11.1747sec\n",
      "반복 7270 || Loss: 3.8302 || 10iter: 9.7463sec\n",
      "반복 7280 || Loss: 3.7229 || 10iter: 9.8289sec\n",
      "반복 7290 || Loss: 3.5734 || 10iter: 10.5717sec\n",
      "반복 7300 || Loss: 4.0723 || 10iter: 9.7707sec\n",
      "반복 7310 || Loss: 3.3285 || 10iter: 10.4999sec\n",
      "반복 7320 || Loss: 3.8597 || 10iter: 10.7364sec\n",
      "반복 7330 || Loss: 3.3675 || 10iter: 10.0868sec\n",
      "---------------------\n",
      "epoch 41 || Epoch_TRAIN_Loss:640.9955 || Epoch_VAL_Loss:0.0000\n",
      "timer:  185.5333 sec.\n",
      "---------------------\n",
      "Epoch 42/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 7340 || Loss: 3.4792 || 10iter: 1.0035sec\n",
      "반복 7350 || Loss: 4.1195 || 10iter: 10.3184sec\n",
      "반복 7360 || Loss: 3.3513 || 10iter: 9.4234sec\n",
      "반복 7370 || Loss: 3.2058 || 10iter: 10.1743sec\n",
      "반복 7380 || Loss: 3.8258 || 10iter: 9.8514sec\n",
      "반복 7390 || Loss: 3.0992 || 10iter: 11.1124sec\n",
      "반복 7400 || Loss: 3.7807 || 10iter: 9.7735sec\n",
      "반복 7410 || Loss: 3.2597 || 10iter: 11.1834sec\n",
      "반복 7420 || Loss: 3.0276 || 10iter: 9.9698sec\n",
      "반복 7430 || Loss: 2.9036 || 10iter: 10.0450sec\n",
      "반복 7440 || Loss: 4.0213 || 10iter: 10.4060sec\n",
      "반복 7450 || Loss: 3.3521 || 10iter: 10.4525sec\n",
      "반복 7460 || Loss: 3.9672 || 10iter: 10.0720sec\n",
      "반복 7470 || Loss: 3.3399 || 10iter: 10.5649sec\n",
      "반복 7480 || Loss: 2.8820 || 10iter: 9.9022sec\n",
      "반복 7490 || Loss: 4.0372 || 10iter: 10.1139sec\n",
      "반복 7500 || Loss: 3.3566 || 10iter: 10.3720sec\n",
      "반복 7510 || Loss: 3.1832 || 10iter: 9.1488sec\n",
      "---------------------\n",
      "epoch 42 || Epoch_TRAIN_Loss:634.6997 || Epoch_VAL_Loss:0.0000\n",
      "timer:  187.1142 sec.\n",
      "---------------------\n",
      "Epoch 43/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 7520 || Loss: 3.6539 || 10iter: 1.9490sec\n",
      "반복 7530 || Loss: 3.6549 || 10iter: 10.6748sec\n",
      "반복 7540 || Loss: 3.7145 || 10iter: 10.0491sec\n",
      "반복 7550 || Loss: 3.6739 || 10iter: 9.9627sec\n",
      "반복 7560 || Loss: 3.8052 || 10iter: 10.0312sec\n",
      "반복 7570 || Loss: 3.2467 || 10iter: 10.0388sec\n",
      "반복 7580 || Loss: 4.1274 || 10iter: 9.6251sec\n",
      "반복 7590 || Loss: 3.1077 || 10iter: 10.0852sec\n",
      "반복 7600 || Loss: 3.4541 || 10iter: 9.9437sec\n",
      "반복 7610 || Loss: 3.8322 || 10iter: 10.6157sec\n",
      "반복 7620 || Loss: 3.9109 || 10iter: 10.2507sec\n",
      "반복 7630 || Loss: 4.0548 || 10iter: 10.4768sec\n",
      "반복 7640 || Loss: 4.2168 || 10iter: 10.1067sec\n",
      "반복 7650 || Loss: 3.4271 || 10iter: 10.2859sec\n",
      "반복 7660 || Loss: 3.4492 || 10iter: 9.8239sec\n",
      "반복 7670 || Loss: 3.3832 || 10iter: 9.7699sec\n",
      "반복 7680 || Loss: 3.5342 || 10iter: 9.6006sec\n",
      "반복 7690 || Loss: 3.7936 || 10iter: 10.5934sec\n",
      "---------------------\n",
      "epoch 43 || Epoch_TRAIN_Loss:633.3758 || Epoch_VAL_Loss:0.0000\n",
      "timer:  186.9404 sec.\n",
      "---------------------\n",
      "Epoch 44/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 7700 || Loss: 3.5035 || 10iter: 2.7966sec\n",
      "반복 7710 || Loss: 3.6929 || 10iter: 9.7534sec\n",
      "반복 7720 || Loss: 3.6618 || 10iter: 10.0955sec\n",
      "반복 7730 || Loss: 3.1800 || 10iter: 9.7954sec\n",
      "반복 7740 || Loss: 3.5800 || 10iter: 10.3207sec\n",
      "반복 7750 || Loss: 3.3307 || 10iter: 10.2205sec\n",
      "반복 7760 || Loss: 3.8554 || 10iter: 9.5667sec\n",
      "반복 7770 || Loss: 3.0728 || 10iter: 10.7983sec\n",
      "반복 7780 || Loss: 3.1477 || 10iter: 9.9432sec\n",
      "반복 7790 || Loss: 2.9506 || 10iter: 10.4242sec\n",
      "반복 7800 || Loss: 3.0200 || 10iter: 10.7328sec\n",
      "반복 7810 || Loss: 3.3560 || 10iter: 9.8139sec\n",
      "반복 7820 || Loss: 3.4480 || 10iter: 10.7228sec\n",
      "반복 7830 || Loss: 3.2632 || 10iter: 9.6513sec\n",
      "반복 7840 || Loss: 3.6430 || 10iter: 11.4674sec\n",
      "반복 7850 || Loss: 3.2935 || 10iter: 9.4143sec\n",
      "반복 7860 || Loss: 3.8239 || 10iter: 11.0165sec\n",
      "반복 7870 || Loss: 3.5430 || 10iter: 9.9716sec\n",
      "---------------------\n",
      "epoch 44 || Epoch_TRAIN_Loss:630.9614 || Epoch_VAL_Loss:0.0000\n",
      "timer:  188.2825 sec.\n",
      "---------------------\n",
      "Epoch 45/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 7880 || Loss: 4.0558 || 10iter: 3.2126sec\n",
      "반복 7890 || Loss: 3.3807 || 10iter: 10.7350sec\n",
      "반복 7900 || Loss: 3.3730 || 10iter: 10.3086sec\n",
      "반복 7910 || Loss: 3.7681 || 10iter: 10.8456sec\n",
      "반복 7920 || Loss: 4.1373 || 10iter: 10.4086sec\n",
      "반복 7930 || Loss: 3.6453 || 10iter: 10.4167sec\n",
      "반복 7940 || Loss: 4.2634 || 10iter: 9.6978sec\n",
      "반복 7950 || Loss: 3.3843 || 10iter: 11.0194sec\n",
      "반복 7960 || Loss: 3.4219 || 10iter: 9.9465sec\n",
      "반복 7970 || Loss: 2.9003 || 10iter: 10.6464sec\n",
      "반복 7980 || Loss: 3.1166 || 10iter: 11.0019sec\n",
      "반복 7990 || Loss: 3.3834 || 10iter: 10.6918sec\n",
      "반복 8000 || Loss: 3.6906 || 10iter: 9.8597sec\n",
      "반복 8010 || Loss: 3.5425 || 10iter: 10.8257sec\n",
      "반복 8020 || Loss: 3.3610 || 10iter: 10.2872sec\n",
      "반복 8030 || Loss: 3.3077 || 10iter: 10.4194sec\n",
      "반복 8040 || Loss: 2.7979 || 10iter: 10.1081sec\n",
      "반복 8050 || Loss: 3.7064 || 10iter: 11.1616sec\n",
      "---------------------\n",
      "epoch 45 || Epoch_TRAIN_Loss:621.2091 || Epoch_VAL_Loss:0.0000\n",
      "timer:  190.9638 sec.\n",
      "---------------------\n",
      "Epoch 46/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 8060 || Loss: 3.4200 || 10iter: 5.4582sec\n",
      "반복 8070 || Loss: 3.5205 || 10iter: 9.6421sec\n",
      "반복 8080 || Loss: 3.7472 || 10iter: 10.2697sec\n",
      "반복 8090 || Loss: 3.3395 || 10iter: 10.0948sec\n",
      "반복 8100 || Loss: 3.5723 || 10iter: 9.5998sec\n",
      "반복 8110 || Loss: 3.1884 || 10iter: 10.8509sec\n",
      "반복 8120 || Loss: 3.6343 || 10iter: 10.5485sec\n",
      "반복 8130 || Loss: 3.4751 || 10iter: 10.4363sec\n",
      "반복 8140 || Loss: 3.8460 || 10iter: 9.7610sec\n",
      "반복 8150 || Loss: 3.3537 || 10iter: 10.7718sec\n",
      "반복 8160 || Loss: 3.4521 || 10iter: 10.1202sec\n",
      "반복 8170 || Loss: 3.3015 || 10iter: 10.0948sec\n",
      "반복 8180 || Loss: 3.6202 || 10iter: 11.0015sec\n",
      "반복 8190 || Loss: 3.2405 || 10iter: 10.3074sec\n",
      "반복 8200 || Loss: 3.2322 || 10iter: 10.1185sec\n",
      "반복 8210 || Loss: 3.5536 || 10iter: 11.0013sec\n",
      "반복 8220 || Loss: 3.0153 || 10iter: 9.8477sec\n",
      "반복 8230 || Loss: 3.3031 || 10iter: 11.0271sec\n",
      "---------------------\n",
      "epoch 46 || Epoch_TRAIN_Loss:616.9464 || Epoch_VAL_Loss:0.0000\n",
      "timer:  189.1448 sec.\n",
      "---------------------\n",
      "Epoch 47/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 8240 || Loss: 3.6759 || 10iter: 6.3749sec\n",
      "반복 8250 || Loss: 3.1221 || 10iter: 10.7293sec\n",
      "반복 8260 || Loss: 2.9742 || 10iter: 10.6834sec\n",
      "반복 8270 || Loss: 3.7062 || 10iter: 9.6870sec\n",
      "반복 8280 || Loss: 3.2315 || 10iter: 11.1037sec\n",
      "반복 8290 || Loss: 3.4090 || 10iter: 9.2334sec\n",
      "반복 8300 || Loss: 3.3069 || 10iter: 10.5656sec\n",
      "반복 8310 || Loss: 3.6330 || 10iter: 9.5950sec\n",
      "반복 8320 || Loss: 3.4286 || 10iter: 10.5950sec\n",
      "반복 8330 || Loss: 3.9174 || 10iter: 10.2994sec\n",
      "반복 8340 || Loss: 3.9306 || 10iter: 9.5895sec\n",
      "반복 8350 || Loss: 3.2107 || 10iter: 10.1877sec\n",
      "반복 8360 || Loss: 3.3694 || 10iter: 10.9005sec\n",
      "반복 8370 || Loss: 3.7070 || 10iter: 9.6475sec\n",
      "반복 8380 || Loss: 3.4802 || 10iter: 10.8392sec\n",
      "반복 8390 || Loss: 3.1750 || 10iter: 10.1385sec\n",
      "반복 8400 || Loss: 3.4838 || 10iter: 10.0879sec\n",
      "반복 8410 || Loss: 3.7572 || 10iter: 9.7336sec\n",
      "---------------------\n",
      "epoch 47 || Epoch_TRAIN_Loss:615.9878 || Epoch_VAL_Loss:0.0000\n",
      "timer:  187.6602 sec.\n",
      "---------------------\n",
      "Epoch 48/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 8420 || Loss: 3.2992 || 10iter: 7.4448sec\n",
      "반복 8430 || Loss: 3.1640 || 10iter: 9.8104sec\n",
      "반복 8440 || Loss: 3.0334 || 10iter: 9.4544sec\n",
      "반복 8450 || Loss: 3.2907 || 10iter: 10.2303sec\n",
      "반복 8460 || Loss: 3.1049 || 10iter: 9.5930sec\n",
      "반복 8470 || Loss: 3.5273 || 10iter: 11.1786sec\n",
      "반복 8480 || Loss: 3.4029 || 10iter: 9.9891sec\n",
      "반복 8490 || Loss: 3.5938 || 10iter: 9.5569sec\n",
      "반복 8500 || Loss: 3.3539 || 10iter: 9.7963sec\n",
      "반복 8510 || Loss: 3.4636 || 10iter: 10.8610sec\n",
      "반복 8520 || Loss: 3.7577 || 10iter: 10.6620sec\n",
      "반복 8530 || Loss: 2.9290 || 10iter: 9.5902sec\n",
      "반복 8540 || Loss: 3.6637 || 10iter: 9.4607sec\n",
      "반복 8550 || Loss: 4.0656 || 10iter: 11.5068sec\n",
      "반복 8560 || Loss: 3.5579 || 10iter: 10.7395sec\n",
      "반복 8570 || Loss: 3.8835 || 10iter: 11.1033sec\n",
      "반복 8580 || Loss: 3.4964 || 10iter: 10.5077sec\n",
      "반복 8590 || Loss: 3.6641 || 10iter: 10.8659sec\n",
      "---------------------\n",
      "epoch 48 || Epoch_TRAIN_Loss:616.2954 || Epoch_VAL_Loss:0.0000\n",
      "timer:  188.5750 sec.\n",
      "---------------------\n",
      "Epoch 49/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 8600 || Loss: 3.2473 || 10iter: 7.9638sec\n",
      "반복 8610 || Loss: 3.5868 || 10iter: 10.6044sec\n",
      "반복 8620 || Loss: 3.3172 || 10iter: 11.0206sec\n",
      "반복 8630 || Loss: 3.0017 || 10iter: 9.3765sec\n",
      "반복 8640 || Loss: 3.1283 || 10iter: 10.7666sec\n",
      "반복 8650 || Loss: 2.8965 || 10iter: 9.7850sec\n",
      "반복 8660 || Loss: 3.4033 || 10iter: 10.8002sec\n",
      "반복 8670 || Loss: 3.1826 || 10iter: 10.9855sec\n",
      "반복 8680 || Loss: 2.9873 || 10iter: 10.0340sec\n",
      "반복 8690 || Loss: 3.5330 || 10iter: 10.5831sec\n",
      "반복 8700 || Loss: 3.5353 || 10iter: 9.8710sec\n",
      "반복 8710 || Loss: 3.4652 || 10iter: 10.0470sec\n",
      "반복 8720 || Loss: 3.3476 || 10iter: 10.5693sec\n",
      "반복 8730 || Loss: 3.6612 || 10iter: 10.0303sec\n",
      "반복 8740 || Loss: 3.4571 || 10iter: 9.9669sec\n",
      "반복 8750 || Loss: 4.0136 || 10iter: 10.9294sec\n",
      "반복 8760 || Loss: 2.9566 || 10iter: 10.3852sec\n",
      "반복 8770 || Loss: 3.1355 || 10iter: 9.4432sec\n",
      "---------------------\n",
      "epoch 49 || Epoch_TRAIN_Loss:605.2011 || Epoch_VAL_Loss:0.0000\n",
      "timer:  188.0395 sec.\n",
      "---------------------\n",
      "Epoch 50/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 8780 || Loss: 3.1433 || 10iter: 9.1049sec\n",
      "반복 8790 || Loss: 2.9614 || 10iter: 10.0333sec\n",
      "반복 8800 || Loss: 3.4314 || 10iter: 10.8551sec\n",
      "반복 8810 || Loss: 3.5136 || 10iter: 10.1547sec\n",
      "반복 8820 || Loss: 3.9476 || 10iter: 10.0248sec\n",
      "반복 8830 || Loss: 3.2589 || 10iter: 10.0583sec\n",
      "반복 8840 || Loss: 3.6122 || 10iter: 10.0956sec\n",
      "반복 8850 || Loss: 3.6476 || 10iter: 9.2375sec\n",
      "반복 8860 || Loss: 3.5767 || 10iter: 10.9237sec\n",
      "반복 8870 || Loss: 3.3087 || 10iter: 10.6383sec\n",
      "반복 8880 || Loss: 3.6283 || 10iter: 9.4822sec\n",
      "반복 8890 || Loss: 3.1401 || 10iter: 10.1818sec\n",
      "반복 8900 || Loss: 3.4749 || 10iter: 8.8128sec\n",
      "반복 8910 || Loss: 3.8745 || 10iter: 10.6683sec\n",
      "반복 8920 || Loss: 3.8285 || 10iter: 9.9467sec\n",
      "반복 8930 || Loss: 3.3596 || 10iter: 11.3465sec\n",
      "반복 8940 || Loss: 3.3285 || 10iter: 10.3009sec\n",
      "반복 8950 || Loss: 3.4335 || 10iter: 10.4308sec\n",
      "---------------------\n",
      "  ( val )  \n",
      "---------------------\n",
      "epoch 50 || Epoch_TRAIN_Loss:602.1979 || Epoch_VAL_Loss:682.5720\n",
      "timer:  268.6976 sec.\n",
      "---------------------\n",
      "Epoch 51/50\n",
      "---------------------\n",
      "   ( train )   \n",
      "반복 8960 || Loss: 3.1140 || 10iter: 9.5836sec\n",
      "반복 8970 || Loss: 3.1270 || 10iter: 10.2678sec\n",
      "반복 8980 || Loss: 3.0296 || 10iter: 9.9736sec\n",
      "반복 8990 || Loss: 3.6268 || 10iter: 10.3573sec\n",
      "반복 9000 || Loss: 3.4281 || 10iter: 10.0178sec\n",
      "반복 9010 || Loss: 3.4464 || 10iter: 10.0740sec\n",
      "반복 9020 || Loss: 3.6164 || 10iter: 10.0538sec\n",
      "반복 9030 || Loss: 3.1426 || 10iter: 10.0588sec\n",
      "반복 9040 || Loss: 3.2351 || 10iter: 10.1508sec\n",
      "반복 9050 || Loss: 3.7241 || 10iter: 10.7728sec\n",
      "반복 9060 || Loss: 2.5463 || 10iter: 10.1541sec\n",
      "반복 9070 || Loss: 3.5628 || 10iter: 10.8529sec\n",
      "반복 9080 || Loss: 3.7353 || 10iter: 9.9218sec\n",
      "반복 9090 || Loss: 3.1193 || 10iter: 9.5866sec\n",
      "반복 9100 || Loss: 3.1531 || 10iter: 9.5508sec\n",
      "반복 9110 || Loss: 3.2463 || 10iter: 9.8488sec\n",
      "반복 9120 || Loss: 3.4036 || 10iter: 10.1199sec\n",
      "---------------------\n",
      "epoch 51 || Epoch_TRAIN_Loss:597.7871 || Epoch_VAL_Loss:0.0000\n",
      "timer:  184.0722 sec.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2, 4, 4, -1, -1, 7, -1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf2.5': conda)"
  },
  "interpreter": {
   "hash": "8713644ccf95bc94f9cdb73f3820952989f55b48f58b1b4cb3d9529941d252d1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}