{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 패키지 import\n",
    "from math import sqrt\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# vgg 모듈 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def make_vgg():\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "\n",
    "    cfg = [64,64,\"M\", 128,128,\"M\", 256,256,256,\"MC\",512,512,512,\"M\", 512,512,512]\n",
    "\n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        elif v == \"MC\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "\n",
    "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "    conv6 = nn.Conv2d(512,1024,kernel_size=3, padding=6, dilation=6)\n",
    "    conv7 = nn.Conv2d(1024,1024, kernel_size=1)\n",
    "    layers += [pool5, conv6, nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
    "\n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "vgg_test = make_vgg()\n",
    "print(vgg_test)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "  (32): ReLU(inplace=True)\n",
      "  (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (34): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# extra 모듈 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def make_extras():\n",
    "    layers = []\n",
    "    in_channels = 1024\n",
    "\n",
    "    cfg = [256,512,128,256,128,256,128,256]\n",
    "\n",
    "    layers += [nn.Conv2d(in_channels, cfg[0], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[0], cfg[1], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[1], cfg[2], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[2], cfg[3], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[3], cfg[4], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[4], cfg[5], kernel_size=(3))]\n",
    "    layers += [nn.Conv2d(cfg[5], cfg[5], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[6], cfg[7], kernel_size=(3))]\n",
    "\n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "extra_test = make_extras()\n",
    "print(extra_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# loc 및 conf 모듈 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def make_loc_conf(num_classes=21, bbox_aspect_num=[4,6,6,6,4,4]):\n",
    "    loc_layers=[]\n",
    "    conf_layers=[]\n",
    "\n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[0]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[0]*num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    loc_layers += [nn.Conv2d(1024,bbox_aspect_num[1]*4,kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(1024, bbox_aspect_num[1]*num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    loc_layers += [nn.Conv2d(512,bbox_aspect_num[2]*4,kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[2]*num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    loc_layers += [nn.Conv2d(256,bbox_aspect_num[3]*4,kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[3]*num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    loc_layers += [nn.Conv2d(256,bbox_aspect_num[4]*4,kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[4]*num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    loc_layers += [nn.Conv2d(256,bbox_aspect_num[5]*4,kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[5]*num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    return nn.ModuleList(loc_layers), nn.ModuleList(conf_layers)\n",
    "\n",
    "loc_test, conf_test = make_loc_conf()\n",
    "print(loc_test)\n",
    "print(conf_test)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# L2Norm 층 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class L2Norm(nn.Module):\n",
    "    def __init__(self, input_channel=512, scale=20):\n",
    "        super(L2Norm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_channel))\n",
    "        self.scale = scale\n",
    "        self.reset_parameters()\n",
    "        self.eps = 1e-10\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.constant_(self.weight, self.scale)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt() + self.eps\n",
    "        x = torch.div(x, norm)\n",
    "\n",
    "        weights = self.weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "\n",
    "        out = weights * x\n",
    "        return out\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 디폴트 박스 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class DBox(object):\n",
    "    def __init__(self, cfg):\n",
    "        super(DBox, self).__init__()\n",
    "\n",
    "        self.image_size = cfg[\"input_size\"]\n",
    "        self.feature_maps = cfg[\"feature_maps\"]\n",
    "        self.num_priors = len(cfg[\"feature_maps\"])\n",
    "        self.steps = cfg[\"steps\"]\n",
    "\n",
    "        self.min_sizes = cfg[\"min_sizes\"]\n",
    "        self.max_sizes = cfg[\"max_sizes\"]\n",
    "        self.aspect_ratios = cfg[\"aspect_ratios\"]\n",
    "\n",
    "    def make_dbox_list(self):\n",
    "        mean = []\n",
    "\n",
    "        for k, f in enumerate(self.feature_maps):\n",
    "            for i, j in product(range(f), repeat=2):\n",
    "\n",
    "                f_k = self.image_size / self.steps[k]\n",
    "\n",
    "                cx = (j + 0.5) / f_k\n",
    "                cy = (i + 0.5) / f_k\n",
    "\n",
    "                s_k = self.min_sizes[k] / self.image_size\n",
    "                mean += [cx,cy,s_k,s_k]\n",
    "\n",
    "                s_k_prime = sqrt(s_k * (self.max_sizes[k]/ self.image_size))\n",
    "                mean += [cx,cy,s_k_prime, s_k_prime]\n",
    "\n",
    "                for ar in self.aspect_ratios[k]:\n",
    "                    mean += [cx, cy, s_k * sqrt(ar), s_k/sqrt(ar)]\n",
    "                    mean += [cx, cy, s_k * sqrt(ar), s_k*sqrt(ar)]\n",
    "\n",
    "        output = torch.Tensor(mean).view(-1,4)\n",
    "        output.clamp_(max=1, min=0)\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "ssd_cfg = {\n",
    "    \"num_classes\":21,\n",
    "    \"input_size\":300,\n",
    "    \"bbox_aspect_num\":[4,6,6,6,4,4],\n",
    "    \"feature_maps\":[38,19,10,5,3,1],\n",
    "    \"steps\":[8,16,32,64,100,300],\n",
    "    \"min_sizes\":[30,60,111,162,213,264],\n",
    "    \"max_sizes\":[60,111,162,213,264,315],\n",
    "    \"aspect_ratios\":[[2],[2,3],[2,3],[2,3],[2],[2]]\n",
    "}\n",
    "\n",
    "dbox = DBox(ssd_cfg)\n",
    "dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "pd.DataFrame(dbox_list.numpy())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.961249</td>\n",
       "      <td>0.961249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     0.013333  0.013333  0.100000  0.100000\n",
       "1     0.013333  0.013333  0.141421  0.141421\n",
       "2     0.013333  0.013333  0.141421  0.070711\n",
       "3     0.013333  0.013333  0.141421  0.141421\n",
       "4     0.040000  0.013333  0.100000  0.100000\n",
       "...        ...       ...       ...       ...\n",
       "8727  0.833333  0.833333  1.000000  1.000000\n",
       "8728  0.500000  0.500000  0.880000  0.880000\n",
       "8729  0.500000  0.500000  0.961249  0.961249\n",
       "8730  0.500000  0.500000  1.000000  0.622254\n",
       "8731  0.500000  0.500000  1.000000  1.000000\n",
       "\n",
       "[8732 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SSD 클래스 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class SSD(nn.Module):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()\n",
    "        self.phase = phase\n",
    "        self.num_classes = cfg[\"num_classes\"]\n",
    "\n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(cfg[\"num_classes\"], cfg[\"bbox_aspect_num\"])\n",
    "\n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "        if phase == \"inference\":\n",
    "            self.detect = Detect()\n",
    "\n",
    "ssd_test = SSD(phase=\"train\", cfg=ssd_cfg)\n",
    "print(ssd_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SSD(\n",
      "  (vgg): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (34): ReLU(inplace=True)\n",
      "  )\n",
      "  (extras): ModuleList(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (L2Norm): L2Norm()\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 순전파 함수 구현\n",
    "## decode함수 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def decode(loc, dbox_list):\n",
    "    boxes = torch.cat((dbox_list[:,:2] + loc[:,:2]*0.1*dbox_list[:,2:], dbox_list[:2,2:]*torch.exp(loc[:,2:]*0.2)), dim=1)\n",
    "\n",
    "    boxes[:,:2] -= boxes[:,2:] / 2\n",
    "    boxes[:,2:] += boxes[:,:2]\n",
    "\n",
    "    return boxes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Non-Maximum suppression 함수 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def nm_suppression(boxes, scores, overlap=0.45, top_k=200):\n",
    "    count = 0\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "\n",
    "    area = torch.mul(x2-x1, y2-y1)\n",
    "\n",
    "    tmp_x1 = boxes.new()\n",
    "    tmp_y1 = boxes.new()\n",
    "    tmp_x2 = boxes.new()\n",
    "    tmp_y2 = boxes.new()\n",
    "    tmp_w = boxes.new()\n",
    "    tmp_h = boxes.new()\n",
    "\n",
    "    v, idx = scores.sort(0)\n",
    "\n",
    "    idx = idx[-top_k:]\n",
    "\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]\n",
    "        \n",
    "        keep[count] = i\n",
    "        count+=1\n",
    "\n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "\n",
    "        idx = idx[:-1]\n",
    "\n",
    "        torch.index_select(x1,0,idx,out=tmp_x1)\n",
    "        torch.index_select(y1,0,idx,out=tmp_y1)\n",
    "        torch.index_select(x2,0,idx,out=tmp_x2)\n",
    "        torch.index_select(y2,0,idx,out=tmp_y2)\n",
    "\n",
    "        tmp_x1 = torch.clamp(tmp_x1, min=x1[i])\n",
    "        tmp_y1 = torch.clamp(tmp_y1, min=y1[i])\n",
    "        tmp_x2 = torch.clamp(tmp_x2, min=x2[i])\n",
    "        tmp_y2 = torch.clamp(tmp_y2, min=y2[i])\n",
    "\n",
    "        tmp_w.resize_as_(tmp_x2)\n",
    "        tmp_h.resize_as_(tmp_y2)\n",
    "\n",
    "        tmp_w = tmp_x2 - tmp_x1\n",
    "        tmp_h = tmp_y2 - tmp_y1\n",
    "\n",
    "        tmp_w = torch.clmap(tmp_w, min=0.0)\n",
    "        tmp_h = torch.clamp(tmp_h, min=0.0)\n",
    "\n",
    "        inter = tmp_w * tmp_h\n",
    "\n",
    "        rem_areas = torch.index_select(area,0, idx)\n",
    "        union = (rem_areas - inter) + area[i]\n",
    "        IoU = inter / union\n",
    "        \n",
    "        idx = idx[IoU.le(overlap)]\n",
    "\n",
    "    return keep, count\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detect 클래스 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class Detect(Function):\n",
    "\n",
    "    def __init__(self, conf_thresh=0.01, top_k=200, nms_thresh=0.45):\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.top_k = top_k\n",
    "\n",
    "        self.nms_thresh = nms_thresh\n",
    "\n",
    "    def forward(self, loc_data, conf_data, dbox_list):\n",
    "        num_batch = loc_data.size(0)\n",
    "        num_dbox = loc_data.size(1)\n",
    "        num_classes = conf_data.size(2)\n",
    "\n",
    "        conf_data = self.softmax(conf_data)\n",
    "        output = torch.zeros(num_batch, num_classes, self.top_k, 5)\n",
    "        \n",
    "        conf_preds = conf_data.transpose(2,1)\n",
    "\n",
    "        for i in range(num_batch):\n",
    "            decoded_boxes = decode(loc_data[i], dbox_list)\n",
    "\n",
    "            conf_scores = conf_preds[i].clone()\n",
    "\n",
    "            for cl in range(1, num_classes):\n",
    "                c_mask = conf_scores[cl].gt(self.conf_thresh)\n",
    "\n",
    "                scores = conf_scores[cl][c_mask]\n",
    "\n",
    "                if scores.nelement() == 0:\n",
    "                    continue\n",
    "\n",
    "                l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
    "\n",
    "                boxes = decoded_boxes[l_mask].view(-1,4)\n",
    "\n",
    "                ids, count = nm_suppression(boxes, scores, self.nms_thresh, self.top_k)\n",
    "\n",
    "                output[i,cl,:count] = torch.cat((scores[ids[:count]].unsqueeze(1), boxes[ids[:count]],1))\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "class SSD(nn.Module):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD,self).__init__()\n",
    "\n",
    "        self.phase = phase\n",
    "        self.num_classes = cfg[\"num_classes\"]\n",
    "\n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(cfg[\"num_classes\"], cfg[\"bbox_aspect_num\"])\n",
    "\n",
    "        dbox = DBox(cfg)\n",
    "\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "        if phase == \"inference\":\n",
    "            self.detect = Detect()\n",
    "\n",
    "    def forward(self, x):\n",
    "        sources = list()\n",
    "        loc = list()\n",
    "        conf = list()\n",
    "\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "\n",
    "        source1 = self.L2Norm(x)\n",
    "        sources.append(source1)\n",
    "\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "\n",
    "        sources.append(x)\n",
    "\n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inplace=True)\n",
    "            if k % 2 == 1:\n",
    "                sources.append(x)\n",
    "\n",
    "        for (x,l,c) in zip(sources, self.loc, self.conf):\n",
    "            loc.append(l(x).permute(0,2,3,1).contiguous())\n",
    "            conf.append(c(x).permute(0,2,3,1).contiguous())\n",
    "\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "\n",
    "        loc = loc.view(loc.size(0), -1, 4)\n",
    "        conf = conf.view(conf.size(0), -1, self.num_classes)\n",
    "\n",
    "        output = (loc, conf, self.dbox_list)\n",
    "\n",
    "        if self.phse == \"inference\":\n",
    "            return self.detect(output[0], output[1], output[2])\n",
    "        else:\n",
    "            return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 손실 함수 구현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "class MultiBoxLoss(nn.Module):\n",
    "    def __init__(self, jaccard_thresh=0.5, neq_pos=3, device=\"cpu\"):\n",
    "        super(MultiBoxLoss,self).__init__()\n",
    "        self.jaccard_thresh = jaccard_thresh\n",
    "        self.neqpos_ratio = neq_pos\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "\n",
    "        loc_data, conf_data, dbox_list = predictions\n",
    "\n",
    "        num_batch = loc_data.size(0)\n",
    "        num_dbox = loc_data.size(1)\n",
    "        num_classes = conf_data.size(2)\n",
    "\n",
    "        conf_t_label = torch.LongTensor(num_batch, num_dbox).to(self.device)\n",
    "        loc_t = torch.Tensor(num_batch, num_dbox, 4).to(self.device)\n",
    "\n",
    "        for idx in range(num_batch):\n",
    "            truths = targets[idx][:,:-1].to(self.device)\n",
    "            labels = targets[idx][:,-1].to(self.device)\n",
    "\n",
    "            dbox = dbox_list.to(self.device)\n",
    "\n",
    "            variance = [0.1,0.2]\n",
    "            match(self.jaccard_thresh, truths, dbox, variance, labels, loc_t, conf_t_label, idx)\n",
    "\n",
    "        pos_mask = conf_t_label > 0\n",
    "        pos_idx = pos_mask.unsqueeze(pos_mask.dim()).expand_as(loc_data)\n",
    "\n",
    "        loc_p = loc_data[pos_idx].view(-1,4)\n",
    "        loc_t = loc_t[pos_idx].view(-1,4)\n",
    "\n",
    "        loss_l = F.smooth_l1_loss(loc_p, loc_t, reduction=\"sum\")\n",
    "\n",
    "        batch_conf = conf_data.view(-1, num_classes)\n",
    "\n",
    "        loss_c = F.cross_entropy(batch_conf, conf_t_label.view(-1), reduction=\"none\")\n",
    "\n",
    "\n",
    "        num_pos = pos_mask.long().sum(1, keepdim=True)\n",
    "        loss_c = loss_c.view(num_batch, -1)\n",
    "        loss_c[pos_mask] = 0\n",
    "\n",
    "        _, loss_idx = loss_c.sort(1, descending=True)\n",
    "        _, idx_rank = loss_idx.sort(1)\n",
    "\n",
    "        num_neg = torch.clamp(num_pos * self.negpos_ration, max=num_dbox)\n",
    "\n",
    "        neg_mask = idx_rank < (num_neg).expand_as(idx_rank)\n",
    "\n",
    "        pos_idx_mask = pos_mask.unsqueeze(2).expand_as(conf_data)\n",
    "        neg_idx_mask = neg_mask.unsqueeze(2).expand_as(conf_data)\n",
    "\n",
    "        conf_hnm = conf_data[(pos_idx_mask+neg_idx_mask).gt(0)].view(-1, num_classes)\n",
    "\n",
    "        conf_t_lable_hnm = conf_t_label[(pos_mask+neg_mask).gt(0)]\n",
    "\n",
    "        loss_c = F.cross_entropy(conf_hnm, conf_t_lable_hnm, reduction=\"sum\")\n",
    "\n",
    "        N = num_pos.sum()\n",
    "        loss_l /= N\n",
    "        loss_c /= N\n",
    "\n",
    "        return loss_l, loss_c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf2.5': conda)"
  },
  "interpreter": {
   "hash": "8713644ccf95bc94f9cdb73f3820952989f55b48f58b1b4cb3d9529941d252d1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}