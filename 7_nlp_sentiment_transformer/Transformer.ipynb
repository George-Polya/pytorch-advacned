{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torchtext\n",
    "\n",
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, text_embedding_vectors):\n",
    "        super(Embedder, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings=text_embedding_vectors, freeze=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_vec = self.embeddings(x)\n",
    "\n",
    "        return x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텐서 크기:  torch.Size([24, 256])\n",
      "출력 텐서 크기:  torch.Size([24, 256, 300])\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloader import get_IMDb_DataLoaders_and_TEXT\n",
    "train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(max_length=256, batch_size=24)\n",
    "\n",
    "batch = next(iter(train_dl))\n",
    "\n",
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "\n",
    "x = batch.Text[0]\n",
    "x1 = net1(x)\n",
    "\n",
    "print(\"입력 텐서 크기: \", x.shape)\n",
    "print(\"출력 텐서 크기: \", x1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PositionalEncoder 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model=300, max_seq_len=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # pe = pe.to(device)\n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model,2):\n",
    "                pe[pos,i] = math.sin(pos/ (10000 ** ((2*i)/d_model)))\n",
    "                pe[pos,i+1] = math.cos(pos / (10000 ** ((2*i)/d_model)))\n",
    "\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = math.sqrt(self.d_model) * x + self.pe\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텐서 크기:  torch.Size([24, 256, 300])\n",
      "출력 텐서 크기:  torch.Size([24, 256, 300])\n"
     ]
    }
   ],
   "source": [
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
    "\n",
    "x = batch.Text[0]\n",
    "x1 = net1(x)\n",
    "x2 = net2(x1)\n",
    "\n",
    "print(\"입력 텐서 크기: \", x1.shape)\n",
    "print(\"출력 텐서 크기: \", x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0c8f38a05a53c2939c3a449707bff7fbed115767dc1eebd5b471500306b379e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2.5': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
