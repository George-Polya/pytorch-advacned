{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torchtext\n",
    "\n",
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, text_embedding_vectors):\n",
    "        super(Embedder, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings=text_embedding_vectors, freeze=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_vec = self.embeddings(x)\n",
    "\n",
    "        return x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텐서 크기:  torch.Size([24, 256])\n",
      "출력 텐서 크기:  torch.Size([24, 256, 300])\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloader import get_IMDb_DataLoaders_and_TEXT\n",
    "train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(max_length=256, batch_size=24)\n",
    "\n",
    "batch = next(iter(train_dl))\n",
    "\n",
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "\n",
    "x = batch.Text[0]\n",
    "x1 = net1(x)\n",
    "\n",
    "print(\"입력 텐서 크기: \", x.shape)\n",
    "print(\"출력 텐서 크기: \", x1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PositionalEncoder 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model=300, max_seq_len=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # pe = pe.to(device)\n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model,2):\n",
    "                pe[pos,i] = math.sin(pos/ (10000 ** ((2*i)/d_model)))\n",
    "                pe[pos,i+1] = math.cos(pos / (10000 ** ((2*i)/d_model)))\n",
    "\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = math.sqrt(self.d_model) * x + self.pe\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텐서 크기:  torch.Size([24, 256, 300])\n",
      "출력 텐서 크기:  torch.Size([24, 256, 300])\n"
     ]
    }
   ],
   "source": [
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
    "\n",
    "x = batch.Text[0]\n",
    "x1 = net1(x)\n",
    "x2 = net2(x1)\n",
    "\n",
    "print(\"입력 텐서 크기: \", x1.shape)\n",
    "print(\"출력 텐서 크기: \", x2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Block 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=300):\n",
    "        super().__init__()\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.d_k = d_model\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "\n",
    "        weights = torch.matmul(q, k.transpose(1,2) / math.sqrt(self.d_k))\n",
    "\n",
    "        mask = mask.unsqueeze(1)\n",
    "\n",
    "        weights = weights.masked_fill(mask ==0, -1e9)\n",
    "\n",
    "        normalized_weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        output = torch.matmul(normalized_weights, v)\n",
    "\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, normalized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.attn = Attention(d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x_normalized = self.norm_1(x)\n",
    "        output, normalized_weights = self.attn(x_normalized, x_normalized, x_normalized, mask)\n",
    "\n",
    "        x2 = x + self.dropout_1(output)\n",
    "\n",
    "        x_normalized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normalized2))\n",
    "\n",
    "        return output, normalized_weights\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True])\n",
      "입력 텐서 크기:  torch.Size([24, 256, 300])\n",
      "출력 텐서 크기:  torch.Size([24, 256, 300])\n",
      "Attention 크기:  tensor([[[0.0026, 0.0023, 0.0027,  ..., 0.0058, 0.0049, 0.0029],\n",
      "         [0.0055, 0.0036, 0.0034,  ..., 0.0040, 0.0049, 0.0049],\n",
      "         [0.0044, 0.0043, 0.0029,  ..., 0.0034, 0.0054, 0.0024],\n",
      "         ...,\n",
      "         [0.0027, 0.0036, 0.0039,  ..., 0.0034, 0.0048, 0.0037],\n",
      "         [0.0052, 0.0026, 0.0037,  ..., 0.0037, 0.0053, 0.0041],\n",
      "         [0.0021, 0.0020, 0.0027,  ..., 0.0036, 0.0049, 0.0036]],\n",
      "\n",
      "        [[0.0027, 0.0027, 0.0025,  ..., 0.0034, 0.0043, 0.0030],\n",
      "         [0.0039, 0.0033, 0.0030,  ..., 0.0063, 0.0035, 0.0053],\n",
      "         [0.0041, 0.0056, 0.0034,  ..., 0.0029, 0.0036, 0.0039],\n",
      "         ...,\n",
      "         [0.0057, 0.0033, 0.0032,  ..., 0.0050, 0.0056, 0.0050],\n",
      "         [0.0028, 0.0043, 0.0034,  ..., 0.0047, 0.0041, 0.0048],\n",
      "         [0.0021, 0.0028, 0.0025,  ..., 0.0034, 0.0036, 0.0037]],\n",
      "\n",
      "        [[0.0105, 0.0143, 0.0147,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0235, 0.0155, 0.0130,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0175, 0.0147, 0.0198,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0078, 0.0095, 0.0099,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0078, 0.0094, 0.0093,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0076, 0.0093, 0.0086,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0040, 0.0029, 0.0051,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0074, 0.0055, 0.0065,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0101, 0.0036, 0.0061,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0029, 0.0028, 0.0058,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0029, 0.0027, 0.0053,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0028, 0.0025, 0.0049,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0028, 0.0034, 0.0033,  ..., 0.0052, 0.0033, 0.0031],\n",
      "         [0.0050, 0.0034, 0.0032,  ..., 0.0037, 0.0031, 0.0037],\n",
      "         [0.0036, 0.0025, 0.0038,  ..., 0.0061, 0.0048, 0.0038],\n",
      "         ...,\n",
      "         [0.0047, 0.0029, 0.0031,  ..., 0.0031, 0.0039, 0.0053],\n",
      "         [0.0036, 0.0034, 0.0026,  ..., 0.0042, 0.0042, 0.0046],\n",
      "         [0.0022, 0.0021, 0.0024,  ..., 0.0050, 0.0034, 0.0038]],\n",
      "\n",
      "        [[0.0028, 0.0044, 0.0028,  ..., 0.0038, 0.0054, 0.0031],\n",
      "         [0.0068, 0.0036, 0.0042,  ..., 0.0059, 0.0032, 0.0052],\n",
      "         [0.0047, 0.0056, 0.0031,  ..., 0.0046, 0.0042, 0.0025],\n",
      "         ...,\n",
      "         [0.0050, 0.0046, 0.0037,  ..., 0.0067, 0.0031, 0.0043],\n",
      "         [0.0065, 0.0025, 0.0043,  ..., 0.0045, 0.0030, 0.0060],\n",
      "         [0.0022, 0.0030, 0.0028,  ..., 0.0048, 0.0040, 0.0037]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
    "net3 = TransformerBlock(d_model=300)\n",
    "\n",
    "x = batch.Text[0]\n",
    "input_pad = 1\n",
    "input_mask = (x != input_pad)\n",
    "print(input_mask[0])\n",
    "\n",
    "x1 = net1(x)\n",
    "x2 = net2(x1)\n",
    "x3, normalized_weights = net3(x2, input_mask)\n",
    "\n",
    "print(\"입력 텐서 크기: \", x2.shape)\n",
    "print(\"출력 텐서 크기: \", x3.shape)\n",
    "print(\"Attention 크기: \", normalized_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClassificationHead 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    '''Transformer_Block의 출력을 사용하여, 마지막에 클래스 분류를 시킨다'''\n",
    "\n",
    "    def __init__(self, d_model=300, output_dim=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # 전결합층\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # output_dim은 음성, 양성의 두 가지\n",
    "\n",
    "        # 가중치 초기화\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 각 미니 배치의 각 문장의 선두 단어의 특징량(300차원)을 꺼낸다\n",
    "        out = self.linear(x0)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassification(nn.Module):\n",
    "\n",
    "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net1 = Embedder(text_embedding_vectors)\n",
    "        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        self.net3_1 = TransformerBlock(d_model=d_model)\n",
    "        self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x1 = self.net1(x)\n",
    "        x2 = self.net2(x1)\n",
    "        x3_1, normalized_weights_1 = self.net3_1(x2, mask)\n",
    "        x3_2, normalized_weights_2 = self.net3_2(x3_1, mask)\n",
    "        x4 = self.net4(x3_2)\n",
    "\n",
    "        return x4, normalized_weights_1, normalized_weights_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텐서 크기:  torch.Size([24, 2])\n",
      "출력 텐서의 sigmoid:  tensor([[0.1473, 0.8527],\n",
      "        [0.1597, 0.8403],\n",
      "        [0.1337, 0.8663],\n",
      "        [0.1585, 0.8415],\n",
      "        [0.1592, 0.8408],\n",
      "        [0.1511, 0.8489],\n",
      "        [0.1548, 0.8452],\n",
      "        [0.1749, 0.8251],\n",
      "        [0.1539, 0.8461],\n",
      "        [0.1497, 0.8503],\n",
      "        [0.1511, 0.8489],\n",
      "        [0.1515, 0.8485],\n",
      "        [0.1455, 0.8545],\n",
      "        [0.1440, 0.8560],\n",
      "        [0.1420, 0.8580],\n",
      "        [0.1330, 0.8670],\n",
      "        [0.1553, 0.8447],\n",
      "        [0.1740, 0.8260],\n",
      "        [0.1638, 0.8362],\n",
      "        [0.1584, 0.8416],\n",
      "        [0.1300, 0.8700],\n",
      "        [0.1471, 0.8529],\n",
      "        [0.1316, 0.8684],\n",
      "        [0.1569, 0.8431]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "\n",
    "net = TransformerClassification(text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)\n",
    "\n",
    "x = batch.Text[0]\n",
    "input_mask = (x != input_pad)\n",
    "out, normalized_weights_1, normalized_weights_2 = net(x, input_mask)\n",
    "\n",
    "print(\"출력 텐서 크기: \", out.shape)\n",
    "print(\"출력 텐서의 sigmoid: \", F.softmax(out, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0c8f38a05a53c2939c3a449707bff7fbed115767dc1eebd5b471500306b379e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2.5': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
