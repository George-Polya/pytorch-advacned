{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오픈포즈 네트워크 구성 및 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenPoseNet 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPoseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OpenPoseNet, self).__init__()\n",
    "\n",
    "        self.model0 = OpenPose_Feature()\n",
    "\n",
    "        # PAFs \n",
    "        self.model1_1 = make_OpenPose_block(\"block1_1\")\n",
    "        self.model2_1 = make_OpenPose_block(\"block2_1\")\n",
    "        self.model3_1 = make_OpenPose_block(\"block3_1\")\n",
    "        self.model4_1 = make_OpenPose_block(\"block4_1\")\n",
    "        self.model5_1 = make_OpenPose_block(\"block5_1\")\n",
    "        self.model6_1 = make_OpenPose_block(\"block6_1\")\n",
    "\n",
    "        # confidence heatmap\n",
    "        self.model1_2 = make_OpenPose_block(\"block1_2\")\n",
    "        self.model2_2 = make_OpenPose_block(\"block2_2\")\n",
    "        self.model3_2 = make_OpenPose_block(\"block3_2\")\n",
    "        self.model4_2 = make_OpenPose_block(\"block4_2\")\n",
    "        self.model5_2 = make_OpenPose_block(\"block5_2\")\n",
    "        self.model6_2 = make_OpenPose_block(\"block6_2\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.model0(x)\n",
    "\n",
    "        out1_1 = self.model1_1(out1)\n",
    "        out1_2 = self.model1_2(out1)\n",
    "\n",
    "        out2 = torch.cat([out1_1, out1_2, out1], 1)\n",
    "        out2_1 = self.model2_1(out2)\n",
    "        out2_2 = self.model2_2(out2)\n",
    "\n",
    "        out3 = torch.cat([out2_1, out2_2, out1], 1)\n",
    "        out3_1 = self.model3_1(out3)\n",
    "        out3_2 = self.model3_2(out3)\n",
    "\n",
    "        out4 = torch.cat([out3_1, out3_2, out1], 1)\n",
    "        out4_1 = self.model4_1(out4)\n",
    "        out4_2 = self.model4_2(out4)\n",
    "\n",
    "        out5 = torch.cat([out4_1, out4_2, out1], 1)\n",
    "        out5_1 = self.model5_1(out5)\n",
    "        out5_2 = self.model5_2(out5)\n",
    "\n",
    "        out6 = torch.cat([out5_1, out5_2, out1], 1)\n",
    "        out6_1 = self.model6_1(out6)\n",
    "        out6_2 = self.model6_2(out6)\n",
    "\n",
    "\n",
    "        # 손실 계산을 위한 스테이지 결과 저장\n",
    "        save_for_loss = []\n",
    "        save_for_loss.append(out1_1)\n",
    "        save_for_loss.append(out1_2)\n",
    "        save_for_loss.append(out2_1)\n",
    "        save_for_loss.append(out2_2)\n",
    "        save_for_loss.append(out3_1)\n",
    "        save_for_loss.append(out3_2)\n",
    "        save_for_loss.append(out4_1)\n",
    "        save_for_loss.append(out4_2)\n",
    "        save_for_loss.append(out5_1)\n",
    "        save_for_loss.append(out5_2)\n",
    "        save_for_loss.append(out6_1)\n",
    "        save_for_loss.append(out6_2)\n",
    "\n",
    "        return (out6_1, out6_2), save_for_loss"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0c8f38a05a53c2939c3a449707bff7fbed115767dc1eebd5b471500306b379e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2.5': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
