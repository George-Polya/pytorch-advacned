{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오픈 포즈 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# 초기 설정\n",
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로더 및 네트워크 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import *\n",
    "\n",
    "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(rootpath=\"./data/\")\n",
    "\n",
    "train_dataset = COCOkeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase=\"train\", transform=DataTransform())\n",
    "# val_dataset = COCOkeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase=\"val\", transform=DataTransform())\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders_dict = {\"train\" : train_dataloader, \"val\" : None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openpose_net import OpenPoseNet\n",
    "net = OpenPoseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPoseLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OpenPoseLoss, self).__init__()\n",
    "\n",
    "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
    "        total_loss = 0\n",
    "\n",
    "        for j in range(6):\n",
    "            pred1 = saved_for_loss[2 * j] * paf_mask\n",
    "            gt1 = paf_target.float() * paf_mask\n",
    "\n",
    "            pred2 = saved_for_loss[2*j + 1] * heat_mask\n",
    "            gt2 = heatmap_target.float() * heat_mask\n",
    "\n",
    "            total_loss += F.mse_loss(pred1, gt1, reduction=\"mean\") + F.mse_loss(pred2, gt2, reduction=\"mean\")\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "criterion = OpenPoseLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(),lr=1e-2, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시키는 함수 작성\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPU가 사용 가능한지 확인\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"사용 장치: \", device)\n",
    "\n",
    "    # 네트워크를 GPU로\n",
    "    net.to(device)\n",
    "\n",
    "    # 네트워크가 어느 정도 고정되면, 고속화시킨다\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 화상의 매수\n",
    "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    # 반복 카운터 설정\n",
    "    iteration = 1\n",
    "\n",
    "    # epoch 루프\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 개시 시간을 저장\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0.0  # epoch의 손실합\n",
    "        epoch_val_loss = 0.0  # epoch의 손실합\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epoch별 훈련 및 검증 루프\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # 모델을 훈련 모드로\n",
    "                optimizer.zero_grad()\n",
    "                print('(train)')\n",
    "\n",
    "            # 이번에는 검증을 생략\n",
    "            else:\n",
    "                continue\n",
    "                # net.eval()   # 모델을 검증 모드로\n",
    "                # print('-------------')\n",
    "                # print('(val)')\n",
    "\n",
    "            # 데이터 로더에서 minibatch씩 꺼내는 루프\n",
    "            for imges, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict[phase]:\n",
    "                # 미니 배치 크기가 1이면, 배치 노멀라이제이션에서 에러가 발생하므로 피한다\n",
    "                if imges.size()[0] == 1:\n",
    "                    continue\n",
    "\n",
    "                # GPU가 사용 가능하면 GPU로 데이터를 보낸다\n",
    "                imges = imges.to(device)\n",
    "                heatmap_target = heatmap_target.to(device)\n",
    "                heat_mask = heat_mask.to(device)\n",
    "                paf_target = paf_target.to(device)\n",
    "                paf_mask = paf_mask.to(device)\n",
    "\n",
    "                # optimizer 초기화\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 순전파(forward) 계산\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # (out6_1, out6_2)는 사용하지 않으므로 _ 로 대체\n",
    "                    _, saved_for_loss = net(imges)\n",
    "\n",
    "                    loss = criterion(saved_for_loss, heatmap_target,\n",
    "                                     heat_mask, paf_target, paf_mask)\n",
    "                    del saved_for_loss\n",
    "                    # 훈련시에는 역전파\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if (iteration % 10 == 0):  # 10iter에 1번, loss를 표시\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('반복 {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item()/batch_size, duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 검증시\n",
    "                    # else:\n",
    "                        #epoch_val_loss += loss.item()\n",
    "\n",
    "        # epoch의 phase별 loss와 정답률\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss/num_train_imgs, 0))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "    # 마지막 네트워크를 저장한다\n",
    "    torch.save(net.state_dict(), 'weights/openpose_net_' +\n",
    "               str(epoch+1) + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 장치:  cuda:0\n",
      "-------------\n",
      "Epoch 1/2\n",
      "-------------\n",
      "(train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plass-heesu/.conda/envs/tf2.5/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 10 || Loss: 0.0093 || 10iter: 26.2554 sec.\n",
      "반복 20 || Loss: 0.0082 || 10iter: 20.3005 sec.\n",
      "반복 30 || Loss: 0.0068 || 10iter: 19.7967 sec.\n",
      "반복 40 || Loss: 0.0057 || 10iter: 19.7051 sec.\n",
      "반복 50 || Loss: 0.0048 || 10iter: 19.5485 sec.\n",
      "반복 60 || Loss: 0.0044 || 10iter: 19.8280 sec.\n",
      "반복 70 || Loss: 0.0037 || 10iter: 20.1313 sec.\n",
      "반복 80 || Loss: 0.0030 || 10iter: 20.0685 sec.\n",
      "반복 90 || Loss: 0.0027 || 10iter: 19.5284 sec.\n",
      "반복 100 || Loss: 0.0026 || 10iter: 20.0230 sec.\n",
      "반복 110 || Loss: 0.0021 || 10iter: 19.6482 sec.\n",
      "반복 120 || Loss: 0.0022 || 10iter: 19.9070 sec.\n",
      "반복 130 || Loss: 0.0020 || 10iter: 19.8089 sec.\n",
      "반복 140 || Loss: 0.0018 || 10iter: 19.4712 sec.\n",
      "반복 150 || Loss: 0.0019 || 10iter: 19.7283 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:0.0043 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  315.9997 sec.\n",
      "-------------\n",
      "Epoch 2/2\n",
      "-------------\n",
      "(train)\n",
      "반복 160 || Loss: 0.0017 || 10iter: 13.8279 sec.\n",
      "반복 170 || Loss: 0.0016 || 10iter: 19.7668 sec.\n",
      "반복 180 || Loss: 0.0020 || 10iter: 20.7655 sec.\n",
      "반복 190 || Loss: 0.0016 || 10iter: 19.4699 sec.\n",
      "반복 200 || Loss: 0.0016 || 10iter: 19.8447 sec.\n",
      "반복 210 || Loss: 0.0014 || 10iter: 20.0515 sec.\n",
      "반복 220 || Loss: 0.0017 || 10iter: 19.7526 sec.\n",
      "반복 230 || Loss: 0.0013 || 10iter: 20.0696 sec.\n",
      "반복 240 || Loss: 0.0013 || 10iter: 19.9784 sec.\n",
      "반복 250 || Loss: 0.0015 || 10iter: 19.8003 sec.\n",
      "반복 260 || Loss: 0.0013 || 10iter: 19.6266 sec.\n",
      "반복 270 || Loss: 0.0016 || 10iter: 20.0379 sec.\n",
      "반복 280 || Loss: 0.0015 || 10iter: 20.2981 sec.\n",
      "반복 290 || Loss: 0.0014 || 10iter: 19.2841 sec.\n",
      "반복 300 || Loss: 0.0014 || 10iter: 19.6836 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:0.0015 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  307.5002 sec.\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 검증을 실행한다\n",
    "num_epochs = 2\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0c8f38a05a53c2939c3a449707bff7fbed115767dc1eebd5b471500306b379e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2.5': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
